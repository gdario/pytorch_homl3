{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfe6779",
   "metadata": {},
   "source": [
    "# Chapter 10\n",
    "\n",
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8601b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76b9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../data'\n",
    "full_train_dset = FashionMNIST(root=root_dir, train=True, transform=ToTensor())\n",
    "test_dset = FashionMNIST(root=root_dir, train=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30ae606",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4c46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = Subset(full_train_dset, indices=range(55000))\n",
    "valid_dset = Subset(full_train_dset, indices=range(55000, 60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39bf7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dset), len(valid_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f761d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # Default batch size on keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef43a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5f4d3",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "In Geron's book the data are normalized by dividing by 255. The `ToTensor()` transform added to the Dataset definition takes care of this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c94788",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, tgt = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788b4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6fe9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02309bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential_model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=784, out_features=300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=300, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features=10))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sequential_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c057db0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model = MyModel()\n",
    "classif_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5596b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0266, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22176dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0204,  0.0288, -0.0225,  0.0327, -0.0294, -0.0334, -0.0026, -0.0229,\n",
       "         0.0068, -0.0127], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].weight[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce2bc7",
   "metadata": {},
   "source": [
    "## Weight initialization\n",
    "\n",
    "In Keras weights in a dense layer are, [by default](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense), initialized with a Glorot Uniform initialization.\n",
    "\n",
    "In Pytorch weights in a linear layer are, [by default](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) initialized with a uniform distribution with  U(âˆ’k,k) where k=1/in_features. This is essentially a LeCun uniform initialization. Note that in PyTorch, Glorot initialization is called Xavier initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9437ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf40d666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19df074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cecb27f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0656, -0.0106,  0.0261,  0.0037, -0.0222,  0.0252, -0.0580, -0.0723,\n",
       "         0.0665, -0.0372], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].weight[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f506245",
   "metadata": {},
   "source": [
    "Both the bias and the weight look different. We assume that we are using the same initialization approach as Keras.\n",
    "\n",
    "The Keras model has a final softmax activation. If we use PyTorch cross-entropy loss, the softmax is fused in the loss, so we don't need to include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74120b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d87bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b844b7f",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "The example in Geron's book uses the \"sgd\" optimizer, which I suspect corresponds to the [default settings](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/SGD), i.e., lr = 0.01 and momentum = 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7487429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_optim = optim.SGD(classif_model.parameters(), lr=0.01, momentum=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e26dc5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x)\n",
    "        batch_loss = loss_fn(preds, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 250 == 0:\n",
    "            print(f'Train loss: {batch_loss.item():>.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67df4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            total_loss += loss_fn(preds, y).item()\n",
    "            correct += (preds.argmax(1) == y).type(torch.float).sum().item()\n",
    "    avg_batch_loss = total_loss / num_batches\n",
    "    accuracy = correct / num_obs\n",
    "    print('Validation:')\n",
    "    print(f'\\nAverage loss: {avg_batch_loss:>.5} - Accuracy: {accuracy:>.3}')\n",
    "    return avg_batch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffd85440",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aef7cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 1 -----\n",
      "\n",
      "Train loss: 2.3058\n",
      "Train loss: 1.0391\n",
      "Train loss: 0.85956\n",
      "Train loss: 0.3464\n",
      "Train loss: 0.53134\n",
      "Train loss: 0.72127\n",
      "Train loss: 0.48757\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.50148 - Accuracy: 0.822\n",
      "\n",
      "----- Epoch: 2 -----\n",
      "\n",
      "Train loss: 0.44929\n",
      "Train loss: 0.38813\n",
      "Train loss: 0.49855\n",
      "Train loss: 0.49606\n",
      "Train loss: 0.27502\n",
      "Train loss: 0.52811\n",
      "Train loss: 0.36798\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.43963 - Accuracy: 0.842\n",
      "\n",
      "----- Epoch: 3 -----\n",
      "\n",
      "Train loss: 0.35291\n",
      "Train loss: 0.31095\n",
      "Train loss: 0.48646\n",
      "Train loss: 0.35662\n",
      "Train loss: 0.70252\n",
      "Train loss: 0.44499\n",
      "Train loss: 0.6641\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.43742 - Accuracy: 0.841\n",
      "\n",
      "----- Epoch: 4 -----\n",
      "\n",
      "Train loss: 0.328\n",
      "Train loss: 0.41367\n",
      "Train loss: 0.49587\n",
      "Train loss: 0.50233\n",
      "Train loss: 0.42328\n",
      "Train loss: 0.35917\n",
      "Train loss: 0.57238\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.40377 - Accuracy: 0.855\n",
      "\n",
      "----- Epoch: 5 -----\n",
      "\n",
      "Train loss: 0.27483\n",
      "Train loss: 0.22167\n",
      "Train loss: 0.56337\n",
      "Train loss: 0.26774\n",
      "Train loss: 0.50743\n",
      "Train loss: 0.59859\n",
      "Train loss: 0.47356\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.39001 - Accuracy: 0.859\n",
      "\n",
      "----- Epoch: 6 -----\n",
      "\n",
      "Train loss: 0.5398\n",
      "Train loss: 0.71106\n",
      "Train loss: 0.54808\n",
      "Train loss: 0.34513\n",
      "Train loss: 0.30685\n",
      "Train loss: 0.46433\n",
      "Train loss: 0.3679\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.37036 - Accuracy: 0.865\n",
      "\n",
      "----- Epoch: 7 -----\n",
      "\n",
      "Train loss: 0.35813\n",
      "Train loss: 0.39807\n",
      "Train loss: 0.39706\n",
      "Train loss: 0.29385\n",
      "Train loss: 0.35654\n",
      "Train loss: 0.41844\n",
      "Train loss: 0.60831\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.39796 - Accuracy: 0.857\n",
      "\n",
      "----- Epoch: 8 -----\n",
      "\n",
      "Train loss: 0.31285\n",
      "Train loss: 0.16134\n",
      "Train loss: 0.23302\n",
      "Train loss: 0.31981\n",
      "Train loss: 0.13861\n",
      "Train loss: 0.12089\n",
      "Train loss: 0.2914\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.36114 - Accuracy: 0.871\n",
      "\n",
      "----- Epoch: 9 -----\n",
      "\n",
      "Train loss: 0.12473\n",
      "Train loss: 0.22484\n",
      "Train loss: 0.27293\n",
      "Train loss: 0.48002\n",
      "Train loss: 0.23134\n",
      "Train loss: 0.23904\n",
      "Train loss: 0.27645\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.34276 - Accuracy: 0.875\n",
      "\n",
      "----- Epoch: 10 -----\n",
      "\n",
      "Train loss: 0.22701\n",
      "Train loss: 0.15186\n",
      "Train loss: 0.35884\n",
      "Train loss: 0.29245\n",
      "Train loss: 0.19565\n",
      "Train loss: 0.14795\n",
      "Train loss: 0.18442\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.38403 - Accuracy: 0.859\n",
      "\n",
      "----- Epoch: 11 -----\n",
      "\n",
      "Train loss: 0.40309\n",
      "Train loss: 0.30328\n",
      "Train loss: 0.60162\n",
      "Train loss: 0.45291\n",
      "Train loss: 0.36893\n",
      "Train loss: 0.20002\n",
      "Train loss: 0.22898\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33624 - Accuracy: 0.88\n",
      "\n",
      "----- Epoch: 12 -----\n",
      "\n",
      "Train loss: 0.29008\n",
      "Train loss: 0.43315\n",
      "Train loss: 0.44833\n",
      "Train loss: 0.35468\n",
      "Train loss: 0.39402\n",
      "Train loss: 0.23176\n",
      "Train loss: 0.57551\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.35864 - Accuracy: 0.866\n",
      "\n",
      "----- Epoch: 13 -----\n",
      "\n",
      "Train loss: 0.21056\n",
      "Train loss: 0.33088\n",
      "Train loss: 0.16559\n",
      "Train loss: 0.28488\n",
      "Train loss: 0.12731\n",
      "Train loss: 0.39148\n",
      "Train loss: 0.63401\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.34118 - Accuracy: 0.875\n",
      "\n",
      "----- Epoch: 14 -----\n",
      "\n",
      "Train loss: 0.32395\n",
      "Train loss: 0.5598\n",
      "Train loss: 0.366\n",
      "Train loss: 0.21541\n",
      "Train loss: 0.23883\n",
      "Train loss: 0.29944\n",
      "Train loss: 0.29051\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33527 - Accuracy: 0.877\n",
      "\n",
      "----- Epoch: 15 -----\n",
      "\n",
      "Train loss: 0.19235\n",
      "Train loss: 0.42205\n",
      "Train loss: 0.25571\n",
      "Train loss: 0.33918\n",
      "Train loss: 0.44209\n",
      "Train loss: 0.14883\n",
      "Train loss: 0.45539\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.3361 - Accuracy: 0.878\n",
      "\n",
      "----- Epoch: 16 -----\n",
      "\n",
      "Train loss: 0.34899\n",
      "Train loss: 0.61666\n",
      "Train loss: 0.37696\n",
      "Train loss: 0.41118\n",
      "Train loss: 0.36862\n",
      "Train loss: 0.41566\n",
      "Train loss: 0.10516\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32388 - Accuracy: 0.882\n",
      "\n",
      "----- Epoch: 17 -----\n",
      "\n",
      "Train loss: 0.22373\n",
      "Train loss: 0.30763\n",
      "Train loss: 0.2385\n",
      "Train loss: 0.37079\n",
      "Train loss: 0.23885\n",
      "Train loss: 0.23665\n",
      "Train loss: 0.30443\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32491 - Accuracy: 0.881\n",
      "\n",
      "----- Epoch: 18 -----\n",
      "\n",
      "Train loss: 0.30366\n",
      "Train loss: 0.54017\n",
      "Train loss: 0.22828\n",
      "Train loss: 0.15303\n",
      "Train loss: 0.25546\n",
      "Train loss: 0.42537\n",
      "Train loss: 0.38613\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32597 - Accuracy: 0.881\n",
      "\n",
      "----- Epoch: 19 -----\n",
      "\n",
      "Train loss: 0.56482\n",
      "Train loss: 0.25304\n",
      "Train loss: 0.26883\n",
      "Train loss: 0.25661\n",
      "Train loss: 0.2407\n",
      "Train loss: 0.47703\n",
      "Train loss: 0.19436\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.3382 - Accuracy: 0.874\n",
      "\n",
      "----- Epoch: 20 -----\n",
      "\n",
      "Train loss: 0.37629\n",
      "Train loss: 0.18393\n",
      "Train loss: 0.31249\n",
      "Train loss: 0.25285\n",
      "Train loss: 0.25087\n",
      "Train loss: 0.18516\n",
      "Train loss: 0.36281\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31842 - Accuracy: 0.887\n",
      "\n",
      "----- Epoch: 21 -----\n",
      "\n",
      "Train loss: 0.24373\n",
      "Train loss: 0.19306\n",
      "Train loss: 0.20713\n",
      "Train loss: 0.15774\n",
      "Train loss: 0.2697\n",
      "Train loss: 0.060193\n",
      "Train loss: 0.23145\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31354 - Accuracy: 0.884\n",
      "\n",
      "----- Epoch: 22 -----\n",
      "\n",
      "Train loss: 0.053502\n",
      "Train loss: 0.41894\n",
      "Train loss: 0.25158\n",
      "Train loss: 0.1512\n",
      "Train loss: 0.51815\n",
      "Train loss: 0.40727\n",
      "Train loss: 0.12211\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33219 - Accuracy: 0.881\n",
      "\n",
      "----- Epoch: 23 -----\n",
      "\n",
      "Train loss: 0.21155\n",
      "Train loss: 0.32082\n",
      "Train loss: 0.3407\n",
      "Train loss: 0.13657\n",
      "Train loss: 0.38612\n",
      "Train loss: 0.49097\n",
      "Train loss: 0.29433\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31062 - Accuracy: 0.887\n",
      "\n",
      "----- Epoch: 24 -----\n",
      "\n",
      "Train loss: 0.17949\n",
      "Train loss: 0.071545\n",
      "Train loss: 0.30629\n",
      "Train loss: 0.20386\n",
      "Train loss: 0.29443\n",
      "Train loss: 0.27261\n",
      "Train loss: 0.21973\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31575 - Accuracy: 0.883\n",
      "\n",
      "----- Epoch: 25 -----\n",
      "\n",
      "Train loss: 0.22982\n",
      "Train loss: 0.10293\n",
      "Train loss: 0.24281\n",
      "Train loss: 0.21107\n",
      "Train loss: 0.13323\n",
      "Train loss: 0.17284\n",
      "Train loss: 0.3606\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31846 - Accuracy: 0.884\n",
      "\n",
      "----- Epoch: 26 -----\n",
      "\n",
      "Train loss: 0.066947\n",
      "Train loss: 0.15071\n",
      "Train loss: 0.1693\n",
      "Train loss: 0.2145\n",
      "Train loss: 0.4221\n",
      "Train loss: 0.27798\n",
      "Train loss: 0.089475\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31881 - Accuracy: 0.884\n",
      "\n",
      "----- Epoch: 27 -----\n",
      "\n",
      "Train loss: 0.38\n",
      "Train loss: 0.24796\n",
      "Train loss: 0.23789\n",
      "Train loss: 0.44444\n",
      "Train loss: 0.18596\n",
      "Train loss: 0.14301\n",
      "Train loss: 0.25716\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32544 - Accuracy: 0.885\n",
      "\n",
      "----- Epoch: 28 -----\n",
      "\n",
      "Train loss: 0.2497\n",
      "Train loss: 0.11464\n",
      "Train loss: 0.21293\n",
      "Train loss: 0.12985\n",
      "Train loss: 0.10822\n",
      "Train loss: 0.1532\n",
      "Train loss: 0.049752\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33251 - Accuracy: 0.88\n",
      "\n",
      "----- Epoch: 29 -----\n",
      "\n",
      "Train loss: 0.23303\n",
      "Train loss: 0.2132\n",
      "Train loss: 0.24342\n",
      "Train loss: 0.18943\n",
      "Train loss: 0.31086\n",
      "Train loss: 0.23739\n",
      "Train loss: 0.14886\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.30933 - Accuracy: 0.884\n",
      "\n",
      "----- Epoch: 30 -----\n",
      "\n",
      "Train loss: 0.13115\n",
      "Train loss: 0.24848\n",
      "Train loss: 0.24293\n",
      "Train loss: 0.33322\n",
      "Train loss: 0.33447\n",
      "Train loss: 0.24265\n",
      "Train loss: 0.11541\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31 - Accuracy: 0.886\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\n----- Epoch: {epoch+1} -----\\n')\n",
    "    train(train_loader, classif_model, loss_fn, classif_optim)\n",
    "    loss, acc = validate(valid_loader, classif_model, loss_fn)\n",
    "    test_loss.append(loss)\n",
    "    test_accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe0520",
   "metadata": {},
   "source": [
    "This is very similar to the performance shown in Geron's book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8bcfcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGwCAYAAAB2LhWGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABejUlEQVR4nO3deVxU5f4H8M8M++qGsqQg5pYriqZgmiuKZVqaaOaSaBquaZlm5pL9THPBLC3LrdI0M73eNJUyFbebmZgleb2l4VUItRQBgZE5vz++l4FhWGbGgTnA5/16ndfMnDlzzjOPU+fDc57nORpFURQQERER2ZnW3gUgIiIiAhhKiIiISCUYSoiIiEgVGEqIiIhIFRhKiIiISBUYSoiIiEgVGEqIiIhIFRztXQBz6PV6XLt2DV5eXtBoNPYuDhEREZlBURTcuXMHAQEB0GpLbwepEKHk2rVrqFevnr2LQURERFa4cuUK6tatW+p2FSKUeHl5AZAv5e3tbbP96nQ6HDhwABEREXBycrLZfis71pt1WG/WYb1ZjnVmHdabdUqqt7S0NNSrV89wHi9NhQgleZdsvL29bR5K3N3d4e3tzR+gBVhv1mG9WYf1ZjnWmXVYb9Yxp97M7XrBjq5ERESkCgwlREREpAoMJURERKQKVoWS1atXIzg4GK6urggNDUV8fHyJ27/33nt46KGH4ObmhiZNmuDjjz+2qrBERERUeVnc0XXbtm2YOnUqVq9ejU6dOuGDDz5AZGQkzp8/j8DAQJPt16xZg1mzZuHDDz9E+/bt8f3332Ps2LGoUaMG+vXrZ5MvQURERBWfxaFk+fLliI6OxpgxYwAAsbGx2L9/P9asWYNFixaZbP/JJ59g3LhxiIqKAgA0aNAAJ0+exOLFi4sNJdnZ2cjOzja8TktLAyA9fHU6naVFLlbevmy5z6qA9WYd1pt1WG+WY51Zh/VmnZLqzdK6tCiU5OTk4PTp05g5c6bR+oiICBw/frzIz2RnZ8PV1dVonZubG77//nvodLoihw8tWrQI8+fPN1l/4MABuLu7W1Jks8TFxdl8n1UB6806rDfrsN4sxzqzDuvNOkXVW2ZmpkX7sCiU3LhxA7m5ufD19TVa7+vri5SUlCI/07t3b3z00UcYMGAA2rZti9OnT2P9+vXQ6XS4ceMG/P39TT4za9YsTJs2zfA6b/KViIgIm89TEhcXh169enFMugVYb9ZhvVmH9WY51pl1WG/WKane8q50mMuqydMKT4KiKEqxE6PMmTMHKSkp6NixIxRFga+vL0aNGoUlS5bAwcGhyM+4uLjAxcXFZL2Tk1OZ/FDKar+VHevNOqw367DeLMc6sw7rzTpF1Zul9WjR6BsfHx84ODiYtIqkpqaatJ7kcXNzw/r165GZmYnLly8jKSkJ9evXh5eXF3x8fCwqLBEREVVeFoUSZ2dnhIaGmlw3iouLQ3h4eImfdXJyQt26deHg4ICtW7fi8ccfN+uOgURERFQ1WHz5Ztq0aRg+fDjatWuHsLAwrF27FklJSRg/fjwA6Q9y9epVw1wk//73v/H999+jQ4cO+Pvvv7F8+XL8/PPP2LRpk22/CREREVVoFoeSqKgo3Lx5EwsWLEBycjJatGiBvXv3IigoCACQnJyMpKQkw/a5ublYtmwZLly4ACcnJ3Tr1g3Hjx9H/fr1bfYliIgqnfR0QK8HbNi5n0jtrOroGhMTg5iYmCLf27hxo9Hrhx56CGfOnLHmMEREVc+FC8CSJcAnnwA6nYSSevVkqVs3/3nB1x4e9iuvogC//QYcPw6cOCGPv/4KPPAA0LChLI0a5T8GBwNFDGSo8HJygLt35d/LzDvilqucHCAlBUhOLn5ZsQLo0sWuxbQqlBARkY2dPg0sWgR8+aWc6POkpQG//CJLcWrUMAop2oAA1PvrL2g8PIAHH5T1thpNkpkJnDqVH0BOnABu3DDd7tIlWQrPXaHRAIGBxkElL7w0aAAUmtcKigJkZ0s93LkjS1HP8x4zMuQYjo6yODjkPy9lnUajQVBCArQXLwJZWdJalZFh3uO9e1LeatWAVq2MlxYtAE9P29R/YXo9cO0acPmyPBYXOG7eLH1fly8zlBARFUtRgJs34ZSeLicmR0d1/hVqLUUBDh2SMFLw5N2vHzBrlpzM/vtf4MoVWYp6fucO8Pffsvz0EwDAAUBbAFi5Uvan0QABAUBQkCyBgcaPQUGAl1fR5fvjDwkeeSHk7Nn8E3AeZ2egXTsgLAwIDwdatpS/yv/zH+DiRePH9HTZ5x9/AN98Y7wfjUbClbe3cegofLwy4ggg5H53cvs2EB8vS0EPPij1UjCsNGggAakkigL8+acEhkuXTB+TkqQVxBxOToCfH+DvX/QSGmrFF7YthhIisp+cHDm5/vGH/M+14OP/njtlZ6Nv3vZaLeDmBri75z8WfF7Ue87O1gcZjQZo3Fj+eizi3l5W0+uB3bsljHz/vaxzcACGDgVeeUXCSJ6HHpKlOLdvmwQWfVISbp45A5/MTGiuXJFAd/WqLMXMvo3q1fMDSr168tf1iRPyWFhAgISPvBDSpo3pJZlGjYDOnY3XKQqQmmoaVPKe37kj//7F8fSU8OTlJcGl4GPe87xLWffuGS+5uabrCr2nz8nBn9evw7dBA2jz9uXpaf6js7N8l59+Ml6Sk+US12+/Abt25X8fd3f5t84LKXXqyPcvHD6ysoqvE0B+O4GB0iJWMGQUDiA1a8p/QyrGUEJUHs6ehUN0NMJyc6GpVg3o2tXeJSo7er00aRdsUv/zT5OwgT/+kP9ZF7xUYe6+MzLKrvzFCQyUk2yXLvLYtKnlYUenA7ZsARYvBhITZZ2rKxAdDUyfLv0tLFWtmiwFgkyuTofje/eib9++cHJwAK5fN637gs///hu4dUuWs2eN9+/oCISEGIeQevWsC3oaDeDrK8sjjxi/pyhSzosXpW9G4eDh4VF6q8J9ytXp8P3/6k1r7eWuvIBR0PXrwLlzxkHll1/kUtj33+cH0+JoNBI46teX30jhxwcekH+nSqByfAsitVIUYP16YOJEaLOyUAcAunUDIiKA+fOBjh3tXUJjiiIn/Js385cbN4C//jK9dl/cY3q6ZUHD1VVO+AUvJRR4rqtTB19//TUiu3aFk04nJ6zMTFnynpf0WODmnhbT6YAff5T+HklJwObNsgBA7dpyYs0LKq1bF39iyMwE1q0Dli7Nbwnw9gYmTACmTJGTdFnRavODwMMPF71NXgtFXlBJSpKgExYml2XK4J5jJjQaaSmoU6fsj1XeatcGuneXJc+9e6atKjdvyu++cPAIDJRWmCqAoYSqFkUpvz4JmZlATAzwvzl59H37IunePQQdPAjNgQPAgQNA374STtq1K9uyXLwoozpu3DAOHAWDR95zc69Pl0arzf9Lt1atIgMHAgPlJFTSv4lOB8XJSU6S9pr6Oz0dOHlS+gkcOSLPr18Hdu6UBZDm+/Dw/JaUhx+WUPTee9K3I68zqK8v8OKLwPjx8p3UwMsLaN5cFiofjo7S2ta0KTB4sL1LoxoMJVS56PVySaCoDmGXL8s19Y4dgWXLyjYIXLgAPP20NNlqtcCbbyL3xRdxdt8+PLBqFZwWL5awsnevLP37A/PmSTO5rVy8CHz+uSz/6wBpNhcXCRJ5S82acgItfB2/8PX8go9ubpWnU6qnJ9CzpyyABLfTpyWgxMcDR49K3468sAnIX7aOjhJOAfmr9+WXgVGjpG6IyARDCVUseR3lCgeOvOd//FH6X/pHjshfsaNGAf/3f9IZzJY+/1z6CKSny1/FW7dKHxKdTt4PDpam/JkzgTfekMsB//iHLAMHSjgp2NHREr/9BmzfLmUoOD+Qo6NcXvDxkZCR91jU4uMjzfWVJVCUBWdnubQRFiYdU3NzgZ9/zh91ER8v4TgnR0ZczJwpfw1Xkuv+RGWF/4VQxfHdd/I/99I6heX1RC+qU1j16tLJ8NNPgQ0b5AT+2mvA1Kn3P6FTTg7w0kvAqlXy+tFHgc8+k17vRWnUCPj4Y+DVV+USzrZtwI4dMk9FVBQwd6407Zbm8mX5Htu2yV/veRwc5C/7wYOBAQOktYPKhoODhL7WrYGJE/MnFLt1S4ZZMuARmYWhhNTv7FkJI/v2yWuNRnqbF9UL3Zye6J98kt/B8PvvZd9r18olnf79rTuB/PGHnPzzAtOsWcCCBeb9Zdy0qYSX2bMlnHzxhbSufP45MGwY8PrrMrFUQUlJ+S0iBUOaViud6aKiJIjwTtz2odGY/psRUakYSki9Ll8G5syRyxuKIif48eOlZeN+Ryt07ChzMHz6qYSS338HnnxSTuixsdLkbq6vvwaefVZGqNSoIa0fjz9ueZlatJCgcfastJL84x8SoLZsAUaMkO9+/Li0iJw8mf85rVYuDw0eDDz1lPT0JyKqgNQ9iwqpj04HzenTqJmYmN9HwtZu3JDRCU2aSGhQFGDIELmfxqpVths+qdXKyf7f/5ZWChcX4OBB6Ww6YULRU2cXdO+efK5vXwkk7dvL8FFrAklBrVvLBEs//AA89pj0V9iwAejQQerl5En5S/zRR2Vkx7VrwLffAuPGMZAQUYXGUEIlS0sD9u+XSwg9egDVq8MxLAydZ82CY0CAhIVPPzXvvgqlycgA3nxTpmOOjZU+Gj17ysn5s89kfVnw9AQWLpTJrAYOlBE8q1dLn4+VK4sOXykpMtfI//2fvJ4wQTo32vLu16GhwFdfSQiJiJCWos6dJZhdvSrTk8fElO0cF0RE5YiXb8hYUhJw7JgsR4/KkFa93mgTpXp15Oj1cLl9Wy4lbNsmrQ7h4XLPjn79LJvtUqeTCcbmzZOTPSDTVi9eDPTqZdvvV5LgYOnPceiQ9Df56SfpAPv++3L3zD59ZLsjR6TPRkqKzDL50UcSzspKhw4SDMtzjhUiIjtgKKnKcnMldOQFkGPH5N4ZhQUHA506yeyVnTrhXqNG2Ld3Lx6rXRuOX38tf83/9JPs4+hRGSLZoEF+QOncuejZCBVFRpq8+qpcQgHkc2++Kf0j7HWPhq5d5TLMunVyeebXX4HISLmUEhoq5cvNlYmmvvjCvBEytsBAQkSVHENJVaDTSafRgjfASkwE/vUvmV66IAcHaaXo1Cl/CQgw3Z9WC6VDBwkqb74po0+++kqWgwel4+jKlbJ4ewO9e0tAiYyUESGHDwMzZuSPHKldWy4RPf+8OqZTdnCQsgweLKNoVq0C9uyRBQCGDwfWrMm/+RcREd03hpLKQqeTCcSKulX45cvyl31RvLxkAqi8lpCHH5Y+FpYKCpJ+FRMmyKRh33wD/POfchL/808ZVbJ9u7R+NGokM54CclJ/6SW5GVlRt063t+rVgeXLpRPpSy9JS9CSJcCYMWy5ICKyMYaSiig3VybZOnIkP3z88UfxwQOQaa0bNpSlUSN5bN9ehr7a+s6bnp4yR8aAAdIf5YcfJKB89RWQkCCBxNFRTvRz5lSMjppNmsh3YL8OIqIyw1BSkSgKsHu3zNPx88+m77u7G4eOvMeGDeUSjD1OplqttL48/LBMqX7liowmadu27EbTlCUGEiKiMsNQUlF8+610CM3rg1G9OvDcczLhVl4A8fNT/0mzXj1ZiIiICmEoUbuTJ2UEyMGD8trdXYapvvSSzB5KRERUSTCUqNW5c3KZZvduee3sLNOMv/pqxeiDQUREZCGGErX5z39kErEtW6QPiVYLjBwp90IJCrJ36YiIiMoMQ4laXL0qHUHXrZN7qgDA00/LHBnlNTkXERGRHTGU3I9Ll2SpVk2W6tXl0cnJ/H3cuAG89Rbw7rtAdrasi4yUe7G0bVsmxSYiIlIjhhJrKAqwdCkwa1bRc4O4ueUHlIJhpfDz5GSZKTRvVtVHHpEbvHXuXI5fhoiISB0YSiz199/AqFH5HVAbNACysoDbt+UutwBw964sycnm7bNNGwkjvXurf0gvERFRGWEoscTp09LP49IlGQ3zzjtyf5S8IKHTAWlpElBu3wZu3cp/Xvj1rVvSd2TYMGDgQPvdfI6IiEglGErMoSjABx/I7exzcuSuudu3yx1jC3JyAmrVkoWIiIgswj/PS5OeLneEfeEFCSRPPCEtJoUDCREREd0XhpKSJCbKPVs2b5ab1i1ZAuzaxZlUiYiIygAv3xRnyxbpL5KRAfj7A9u2cVQMERFRGWJLSWHZ2UBMjHRAzcgAuncHzpxhICEiIipjDCUFXboEdOoErFkjI2rmzAEOHOC9ZoiIiMoBL9/k+ec/gREjZKhurVrAp58CffrYu1RERERVRpVvKdHk5kI7a5aMqrl1C+jYUS7XMJAQERGVq6rdUpKcjPDXX4fDL7/I6ylTZISNs7N9y0VERFQFVd1QotfD8bHH4PPLL1C8vKBZvx4YNMjepSIiIqqyqu7lG60WuW+/jVsNGuDeiRMMJERERHZWdUMJAKVHDxxeuhRo3NjeRSEiIqryqnQoAcAb4REREakEz8hERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKVoWS1atXIzg4GK6urggNDUV8fHyJ22/evBmtW7eGu7s7/P398dxzz+HmzZtWFZiIiIgqJ4tDybZt2zB16lTMnj0bZ86cQefOnREZGYmkpKQitz969ChGjBiB6Oho/PLLL9i+fTtOnTqFMWPG3HfhiYiIqPKw+N43y5cvR3R0tCFUxMbGYv/+/VizZg0WLVpksv3JkydRv359TJ48GQAQHByMcePGYcmSJcUeIzs7G9nZ2YbXaWlpAACdTgedTmdpkYuVty9b7rMqYL1Zh/VmHdab5Vhn1mG9WaekerO0LjWKoijmbpyTkwN3d3ds374dTz75pGH9lClTkJCQgMOHD5t85vjx4+jWrRt27tyJyMhIpKamYvDgwXjooYfw/vvvF3mcefPmYf78+Sbrt2zZAnd3d3OLS0RERHaUmZmJZ555Brdv34a3t3ep21vUUnLjxg3k5ubC19fXaL2vry9SUlKK/Ex4eDg2b96MqKgoZGVl4d69e3jiiSewatWqYo8za9YsTJs2zfA6LS0N9erVQ0REhFlfylw6nQ5xcXHo1asXnJycbLbfyo71Zh3Wm3VYb5ZjnVmH9Wadkuot70qHuSy+fAMAGo3G6LWiKCbr8pw/fx6TJ0/G66+/jt69eyM5ORkvv/wyxo8fj3Xr1hX5GRcXF7i4uJisd3JyKpMfSlntt7JjvVmH9WYd1pvlWGfWYb1Zp6h6s7QeLQolPj4+cHBwMGkVSU1NNWk9ybNo0SJ06tQJL7/8MgCgVatW8PDwQOfOnbFw4UL4+/tbVGAiIiKqnCwafePs7IzQ0FDExcUZrY+Li0N4eHiRn8nMzIS20J14HRwcAEgLCxERERFgxZDgadOm4aOPPsL69euRmJiIF198EUlJSRg/fjwA6Q8yYsQIw/b9+vXDl19+iTVr1uD333/HsWPHMHnyZDz88MMICAiw3TchIiKiCs3iPiVRUVG4efMmFixYgOTkZLRo0QJ79+5FUFAQACA5OdlozpJRo0bhzp07ePfddzF9+nRUr14d3bt3x+LFi233LYiIiKjCs6qja0xMDGJiYop8b+PGjSbrJk2ahEmTJllzKCIiIqoieO8bIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFhhIiIiJSBYYSIiIiUgWGEiIiIlIFq0LJ6tWrERwcDFdXV4SGhiI+Pr7YbUeNGgWNRmOyNG/e3OpCExERUeVjcSjZtm0bpk6ditmzZ+PMmTPo3LkzIiMjkZSUVOT2K1euRHJysmG5cuUKatasiaeffvq+C09ERESVh8WhZPny5YiOjsaYMWPw0EMPITY2FvXq1cOaNWuK3L5atWrw8/MzLD/88AP+/vtvPPfcc/ddeCIiIqo8HC3ZOCcnB6dPn8bMmTON1kdEROD48eNm7WPdunXo2bMngoKCit0mOzsb2dnZhtdpaWkAAJ1OB51OZ0mRS5S3L1vusypgvVmH9WYd1pvlWGfWYb1Zp6R6s7QuLQolN27cQG5uLnx9fY3W+/r6IiUlpdTPJycn4+uvv8aWLVtK3G7RokWYP3++yfoDBw7A3d3dkiKbJS4uzub7rApYb9ZhvVmH9WY51pl1WG/WKareMjMzLdqHRaEkj0ajMXqtKIrJuqJs3LgR1atXx4ABA0rcbtasWZg2bZrhdVpaGurVq4eIiAh4e3tbU+Qi6XQ6xMXFoVevXnBycrLZfis71pt1WG/WYb1ZjnVmHdabdUqqt7wrHeayKJT4+PjAwcHBpFUkNTXVpPWkMEVRsH79egwfPhzOzs4lbuvi4gIXFxeT9U5OTmXyQymr/VZ2rDfrsN6sw3qzHOvMOqw36xRVb5bWo0UdXZ2dnREaGmrSRBMXF4fw8PASP3v48GH85z//QXR0tEUFJCIioqrB4ss306ZNw/Dhw9GuXTuEhYVh7dq1SEpKwvjx4wHIpZerV6/i448/NvrcunXr0KFDB7Ro0cI2JSciIqJKxeJQEhUVhZs3b2LBggVITk5GixYtsHfvXsNomuTkZJM5S27fvo0dO3Zg5cqVtik1ERERVTpWdXSNiYlBTExMke9t3LjRZF21atUs7oFLREREVQvvfUNERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESq4GjvAhARVQW5ubnQ6XTlciydTgdHR0dkZWUhNze3XI5ZGbDeLOfk5GTT/TGUEBGVIUVRkJKSglu3bpXrMf38/HDlyhVoNJpyO25Fx3qzjpeXl832xVBCRFSG8gJJnTp14O7uXi4nO71ej/T0dHh6ekKr5VV6c7HeLKMoCjIzM/Hnn3/aLJgwlBARlZHc3FxDIKlVq1a5HVev1yMnJweurq48uVqA9WY5Nzc36PV6ZGRkIDc3974v57DWiYjKSF4fEnd3dzuXhKjsuLu7Q6vV4t69e/e9L4YSIqIyxv4JVJnl/b4VRbnvfTGUEBERkSowlBARkc117doVU6dONbyuX78+YmNjS/yMRqPBrl277vvYttoPlT+GEiIiMujXrx969uxZ5HsnTpyARqPBjz/+aPF+T506heeff/5+i2dk3rx5CAkJMVmfnJyMyMhImx6LygdDCRERGURHR+PgwYP4448/TN5bv349QkJC0LZtW4v3W7t27XLr8Ovn5wcXF5dyOZaa5OTk2LsI942hhIiIDB5//HHUqVMHGzduNFqfmZmJbdu2ITo6Gjdv3sTQoUNRt25duLu7o2XLlvjss89K3G/hyzcXL15Ely5d4OrqimbNmiEuLs7kM6+88goaN24Md3d3NGjQAHPmzDGMaNq4cSPmz5+Ps2fPQqPRQKPRGMpc+PLNuXPn0L17d7i5uaFWrVp4/vnnkZ6ebnh/1KhRGDBgAJYtW4amTZuidu3amDBhQokz8P7222/o378/fH194enpifbt2+Obb74x2iY7OxszZsxAvXr14OLigkaNGmHdunWG93/55Rc89thj8Pb2hpeXFzp37ozffvsNgOnlLwAYMGAARo0aZVSnCxcuxKhRo1CtWjWMHTu21HrLs3v3brRr1w6urq7w8fHBU089BQBYsGABWrZsafJ9Q0ND8frrrxdbH7bCeUqIiMqLogCZmWV/HL0eyMgAHByAvPk23N0BM0YBOTo6YsSIEdi4cSNef/11w8iK7du3IycnB8OGDUNmZiZCQ0PxyiuvwNvbG3v27MHw4cPRoEEDdOjQwYzi6fHUU0/Bx8cHJ0+eRFpamskJGJCZQjdu3IiAgACcO3cOY8eOhZeXF2bMmIGoqCj8/PPP2LdvnyEMVKtWzWQfmZmZ6NOnDzp27IhTp04hNTUVY8aMwcSJE42C13fffQc/Pz/s3r0bKSkpGDp0KEJCQgwn+sLS09PRt29fLFy4EK6urti0aRP69euHCxcuIDAwEAAwYsQInDhxAu+88w5at26NS5cu4caNGwCAq1evokuXLujatSsOHjwIb29vHDt2zOJhtW+//TbmzJmD1157zax6A4A9e/bgqaeewuzZs/HJJ58gJycHe/bsAQCMHj0a8+fPx6lTp9C+fXsAwE8//YQzZ85g+/btFpXNKkoFcPv2bQWAcvv2bZvuNycnR9m1a5eSk5Nj0/1Wdqw367DerFOR6+3u3bvK+fPnlbt378qK9HRFkWhS/kt6utnlTkxMVAAoBw8eNKzr0qWLMnTo0GI/07dvX2X69OmG148++qgyZcoUw+ugoCBlxYoViqIoyv79+xUHBwflypUrhve//vprBYCyc+fOYo+xZMkSJTQ01PB67ty5SuvWrU22K7iftWvXKjVq1FDSC3z/PXv2KFqtVklJSVEURVFGjhypBAUFKTk5Ocrff/+t5ObmKk8//bQSFRVVbFmK0qxZM2XVqlWKoijKhQsXFABKXFxckdvOmjVLCQ4OLvZ3Xbj+FEVR+vfvr4wcOdLwOigoSBkwYECp5Spcb2FhYcqwYcOK3T4yMlJ54YUXDK+nTp2qdO3atdjtMzIylB9++EFJS0szec/S8zcv3xARkZGmTZsiPDwc69evByCXKuLj4zF69GgAMlPtm2++iVatWqFWrVrw9PTEgQMHkJSUZNb+ExMTERgYiLp16xrWhYWFmWz3xRdf4JFHHoGfnx88PT0xZ84cs49R8FitW7eGh4eHYV2nTp2g1+tx4cIFw7rmzZvDwcHB8Nrf3x+pqanF7jcjIwMzZsxAs2bNUL16dXh6euLXX381lC8hIQEODg549NFHi/x8QkICOnfufN8zoLZr185kXWn1lpCQgB49ehS7z7Fjx+Kzzz5DVlYWdDodNm/ebPi3L2u8fENEVF7c3YECfRnKil6vR1paGry9vfOnS7ewk2l0dDQmTpyI9957Dxs2bEBQUJDhRLZs2TKsWLECsbGxaNmyJTw8PDB16lSzO1oqRUyyVXiCuZMnT2LIkCGYP38+evfujWrVqmHr1q1YtmyZRd9DUZRiJ68ruL5wONBoNNDr9cXu9+WXX8b+/fuxdOlSNGzYEG5ubhg0aJChDtzc3EosV2nva7Vak3oqqo9LwbAFmFdvpR27X79+cHFxwc6dO+Hi4oLs7GwMHDiwxM/YCkMJEVF50WiAQieRMqHXA7m5ciwr7+EyePBgTJkyBVu2bMGmTZswduxYw0k8Pj4e/fv3x7PPPvu/w+lx8eJFPPTQQ2btu1mzZkhKSsK1a9cQEBAAQIYbF3Ts2DEEBQVh9uzZhnWFRwQ5OzsjNze31GNt2rQJGRkZhhP4sWPHoNVq0bhxY7PKW5T4+HiMGjUKTz75JADpY3L58mXD+y1btoRer8fhw4eLHGLdqlUrbNq0CTqdrsjWktq1ayM5OdnwOjc3Fz///DO6detWYrnMqbdWrVrh22+/xXPPPVfkPhwdHTFy5Ehs2LABLi4uGDJkSLmNnOLlGyIiMuHp6YmoqCi8+uqruHbtmtGoj4YNGyIuLg7Hjx9HYmIixo0bh5SUFLP33bNnTzRp0gQjRozA2bNnER8fb3QSzTtGUlIStm7dit9++w3vvPMOdu7cabRN/fr1cenSJSQkJODGjRvIzs42OdawYcPg6uqKkSNH4ueff8Z3332HSZMmYfjw4fD19bWsUgqV78svv0RCQgLOnj2LZ555xqhlpX79+hg5ciRGjx6NXbt24dKlSzh06BA+//xzAMDEiRORlpaGIUOG4IcffsDFixfxySefGC4pde/eHXv27MGePXvw66+/IiYmBrdu3TKrXKXV29y5c/HZZ59h7ty5SExMxLlz57BkyRKjbcaMGYODBw/i66+/LrdLNwBDCRERFSM6Ohp///03evbsaRhRAgBz5sxB27Zt0bt3b3Tt2hV+fn4YMGCA2fvVarXYuXMnsrOz8fDDD2PMmDF48803jbbp378/XnzxRUycOBEhISE4fvw45syZY7TNwIED0adPH3Tr1g21a9cucliyu7s79u/fj7/++gvt27fHoEGD0KNHD7z77ruWVUYhK1asQI0aNRAeHo5+/fqhd+/eJvO3rFmzBoMGDUJMTAyaNm2KsWPHIiMjAwBQq1YtHDx4EOnp6Xj00UcRGhqKDz/80NBqMnr0aIwcORIjRozAo48+iuDg4FJbSQDz6q1r167Yvn07du/ejZCQEHTv3h3/+te/jLZp1KgRwsPD0aRJE7NGVNmKRinq4p7KpKWloVq1arh9+za8vb1ttl+dToe9e/eib9++993ZqCphvVmH9WadilxvWVlZuHTpEoKDg+Hq6lpuxy2yTwmVivWWT1EUNG3aFOPGjcO0adNK3DYzMxOJiYlo3LgxvLy8jN6z9PxtVa2vXr3a8B9ZaGgo4uPjS9w+Ozsbs2fPRlBQEFxcXPDggw8aenUTERGReqSmpmL58uW4evVqsf1OyorFHV23bduGqVOnYvXq1ejUqRM++OADREZG4vz580bNewUNHjwYf/75J9atW4eGDRsiNTXV4gliiIiIqOz5+vrCx8cHa9euRY0aNcr12BaHkuXLlyM6OhpjxowBAMTGxmL//v1Ys2YNFi1aZLL9vn37cPjwYfz++++oWbMmAOkAREREROpjz14dFoWSnJwcnD59GjNnzjRaHxERgePHjxf5mbz59ZcsWYJPPvkEHh4eeOKJJ/DGG28UO1Y6OzvbqBd1WloaALm2XNK9CCyVty9b7rMqYL1Zh/VmnYpcbzqdDoqiQK/Xlzjnha3lnVTyjk3mYb1ZJ6/e7t27Z/LfqaX/3VoUSm7cuIHc3FyTYVS+vr7FDgf7/fffcfToUbi6umLnzp24ceMGYmJi8NdffxXbr2TRokWYP3++yfoDBw6UyVjpom4ERaVjvVmH9Wadilhvjo6O8PPzQ3p6ul3u4Hrnzp1yP2ZlwHqzTN5v+/jx4yZdMzItvNeTVZOnFZ4dr6QZ8/R6PTQaDTZv3my4WdLy5csxaNAgvPfee0W2lsyaNcuot29aWhrq1auHiIgIm4++iYuLQ69evSpcr357Yr1Zh/VmnYpcb1lZWbhy5Qo8PT3LdfSNoii4c+cOvLy8iv1/M5livVnn7t27AIDw8HB4enoavZd3pcNcFoUSHx8fODg4mLSKpKamFjsJjb+/Px544AGjuzc+9NBDUBQF//3vf9GoUSOTz7i4uMDFxcVkvZOTU5n8T6ms9lvZsd6sw3qzTkWst9zcXGg0Gmi12nIdYpp36SHv2GQe1pt18gKco6OjyX+jlv43a1GtOzs7IzQ01KQZNS4uDuHh4UV+plOnTrh27RrSC9zv4d///je0Wq3RzZiIiIioarM4Ck6bNg0fffQR1q9fj8TERLz44otISkrC+PHjAcillxEjRhi2f+aZZ1CrVi0899xzOH/+PI4cOYKXX34Zo0ePLvWmQERERFR1WBxKoqKiEBsbiwULFiAkJARHjhzB3r17ERQUBABITk42ukWyp6cn4uLicOvWLbRr1w7Dhg1Dv3798M4779juWxARkap07doVU6dONbyuX78+YmNjS/yMRqPBrl277vvYttpPSebNm4eQkJAyPUZVZFVH15iYGMTExBT53saNG03WNW3atEL2nCciqmr69euHu3fv4ptvvjF578SJEwgPD8fp06dN7vNSmlOnThnu0msr8+bNw65du5CQkGC0Pjk5udwn/SLbYE8eIiIyiI6OxsGDB01udw8A69evR0hIiMWBBABq165dJlM6FMXPz6/IwRKkfgwlRERk8Pjjj6NOnTomrd6ZmZnYtm0boqOjcfPmTQwdOhR169aFu7s7WrZsWeQdegsqfPnm4sWL6NKlC1xdXdGsWbMiW9NfeeUVNG7cGO7u7mjQoAHmzJljmIxr48aNmD9/Ps6ePQuNRgONRmMoc+HLN+fOnUP37t3h5uaGWrVq4fnnnzcafDFq1CgMGDAAy5YtQ9OmTVG7dm1MmDDBoom/9Ho9FixYgLp168LFxQUhISHYt2+f4f2cnBxMnDgR/v7+cHV1Rf369Y1mQZ83bx4CAwPh4uKCgIAATJ482exjVyZWXb4hIiLLKQpg4VxSVtHrgYwMwMEByBvZ6u4OmDP1hqOjI0aMGIGNGzfi9ddfNwz33L59O3JycjBs2DBkZmYiNDQUr7zyCry9vbFnzx4MHz4cDRo0MOs293q9Hk899RR8fHxw8uRJpKWlGfU/yePl5YWNGzciICAA586dw9ixY+Hl5YUZM2YgKioKP//8M/bt22e41FRw6ok8mZmZ6NOnDzp27IhTp04hNTUVY8aMwcSJE42C13fffQc/Pz/s3r0bKSkpGDp0KEJCQjB27NjSKw3AypUrsWzZMnzwwQdo06YN1q9fjyeeeAK//PILGjVqhHfeeQe7d+/G559/jsDAQFy5cgVXrlwBAHzxxRdYsWIFtm7diubNmyMlJQVnz54167iVDUMJEVE5ycwECs0tVUa0AKobrUlPB8zt0jF69Gi8/fbbOHToELp16wZALt089dRTqFGjBmrUqIGXXnrJsP2kSZOwb98+bN++3axQ8s033yAxMRGXL182TA3xf//3f4iMjDTa7rXXXjM8r1+/PqZPn45t27ZhxowZcHNzg6enp2HW3OJs3rwZd+/exccff2zo0/Luu++iX79+WLx4sWGOrRo1amDVqlXIyMhAu3bt8Nhjj+Hbb781O5QsXboUr7zyCoYMGQIAWLx4Mb777jvExsbivffeQ1JSEho1aoRHHnkEGo3GMDgEAJKSkuDn54eePXvCyckJgYGBePjhh806bmXDyzdERGSkadOmCA8PN9wK5LfffkN8fDxGjx4NQCaFe/PNN9GqVSvUqlULnp6eOHDggNHIy5IkJiYiMDDQaK6qsLAwk+2++OILPPLII/Dz84OnpyfmzJlj9jEKHqt169ZGnWw7deoEvV6PCxcuGNY1b94cDg4Ohtf+/v5ITU016xhpaWm4du0aOnXqZLS+U6dOSExMBCCXiBISEtCkSRNMnjwZBw4cMGz39NNP4+7du2jQoAHGjh2LnTt3mkzXXlUwlBARlRN3d2mxKOslLU2P//73FtLS9IZ1lvYxjY6Oxo4dO5CWloYNGzYgKCgIPXr0AAAsW7YMK1aswIwZM3Dw4EEkJCSgd+/eZt/fp6i70Bae1v3kyZMYMmQIIiMj8dVXX+HMmTOYPXu2xfcQKuk2KAXXF555VKPRWHxTvpJuwdK2bVtcunQJb7zxBu7evYvBgwdj0KBBAIB69erhwoULhluvxMTEoEuXLhXyJpT3i5dviIjKiUZj/iWU+6HXA7m5cixrZ0sfPHgwpkyZgi1btmDTpk0YO3as4QQbHx+P/v3749lnn/3f8fS4ePEiHnroIbP23axZMyQlJeHatWsICAgAIMONCzp27BiCgoIwe/Zsw7rCI4KcnZ2Rm5tb6rE2bdqEjIwMQ2vJsWPHoNVq0bhxY7PKWxpvb28EBATg6NGj6NKli2H98ePHjS7DeHt7IyoqClFRURg0aBD69OmDv/76CzVr1oSbmxueeOIJPPHEE5gwYQKaNm2Kc+fOWTXSqSJjKCEiIhOenp6IiorCq6++itu3b2PUqFGG9xo2bIgdO3bg+PHjqFGjBpYvX46UlBSzQ0nPnj3RpEkTjBgxAsuWLUNaWppR+Mg7RlJSErZu3Yr27dtjz5492Llzp9E29evXx6VLl5CQkIC6devCy8vLZCjwsGHDMHfuXIwcORLz5s3D9evXMWnSJAwfPrzYe7ZZ4+WXX8bcuXPx4IMPIiQkBBs2bEBCQgI2b94MAFixYgX8/f0REhICrVaL7du3w8/PD9WrV8fGjRuRm5uLDh06wN3dHZ988gnc3NyM+p1UFbx8Q0RERYqOjsbff/+Nnj17IjAw0LB+zpw5aNu2LXr37o2uXbvCz88PAwYMMHu/Wq0WO3fuRHZ2Nh5++GGMGTMGb775ptE2/fv3x4svvoiJEyciJCQEx48fx5w5c4y2GThwIPr06YNu3bqhdu3aRQ5Ldnd3x/79+/HXX3+hffv2GDRoEHr06IF3333XssooxeTJkzF9+nRMnz4dLVu2xL59+7B7927DTWc9PT2xePFitGvXDu3bt8fly5exd+9eaLVaVK9eHR9++CE6deqEVq1a4dtvv8U///lP1KpVy6ZlrAg0SlEX91QmLS0N1apVw+3bt+Ht7W2z/ep0Ouzduxd9+/atcHcftSfWm3VYb9apyPWWlZWFS5cuITg4GK6uruV2XL1ej7S0NHh7e/NutxZgvVknMzMTiYmJaNy4Mby8vIzes/T8zVonIiIiVWAoISIiIlVgKCEiIiJVYCghIiIiVWAoISIqYxVgPAGR1fJ+38VNUmcJhhIiojKSN1ooszzuwkdkJ5mZmdDr9XB0vP+pzzh5GhFRGXFwcED16tUN91Bxd3e3yV+TpdHr9cjJyUFWVhaHtlqA9WYZRVGQmZmJ69ev486dO0b3DrIWQwkRURnKu4OtuTd3swVFUXD37l24ubmVSwiqLFhv1vH29sbFixdtsi+GEiKiMqTRaODv7486deqU2w3WdDodjhw5gi5dulS4CefsifVmOScnJ4tvXFgShhIionLg4OBgk+Ztc4917949uLq68uRqAdabdWwZSnjRjIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVMGqULJ69WoEBwfD1dUVoaGhiI+PL3bbQ4cOQaPRmCy//vqr1YUmIiKiysfiULJt2zZMnToVs2fPxpkzZ9C5c2dERkYiKSmpxM9duHABycnJhqVRo0ZWF9qWbt1yhqLYuxRERERkcShZvnw5oqOjMWbMGDz00EOIjY1FvXr1sGbNmhI/V6dOHfj5+RkWBwcHqwttK5MmaTFmTG98953G3kUhIiKq8hwt2TgnJwenT5/GzJkzjdZHRETg+PHjJX62TZs2yMrKQrNmzfDaa6+hW7duxW6bnZ2N7Oxsw+u0tDQAgE6ng06ns6TIpbp3zwmrVunRvbtt91uZ5f0b2PrforJjvVmH9WY51pl1WG/WKaneLK1Li0LJjRs3kJubC19fX6P1vr6+SElJKfIz/v7+WLt2LUJDQ5GdnY1PPvkEPXr0wKFDh9ClS5ciP7No0SLMnz/fZP2BAwfg7u5uSZFL1KqVJ4Ae2LvXAevWfQN//0yb7bsqiIuLs3cRKiTWm3VYb5ZjnVmH9WadouotM9Oy86pFoSSPRmN8uUNRFJN1eZo0aYImTZoYXoeFheHKlStYunRpsaFk1qxZmDZtmuF1Wloa6tWrh4iICHh7e1tT5CLpdDqsW/cnfvzRF7/+2h3R0Xqb7bsy0+l0iIuLQ69eveDk5GTv4lQYrDfrsN4sxzqzDuvNOiXVW96VDnNZFEp8fHzg4OBg0iqSmppq0npSko4dO+LTTz8t9n0XFxe4uLiYrHdycrL5D+Wxx37Hjz/6YsMGB7zxhgO8vGy6+0qtLP49qgLWm3VYb5ZjnVmH9WadourN0nq0qKOrs7MzQkNDTZpo4uLiEB4ebvZ+zpw5A39/f0sOXWbatElFo0YK0tKATZvsXRoiIqKqy+LLN9OmTcPw4cPRrl07hIWFYe3atUhKSsL48eMByKWXq1ev4uOPPwYAxMbGon79+mjevDlycnLw6aefYseOHdixY4dtv4mVtFpg4kQ9pkxxwKpVQEyMrCMiIqLyZXEoiYqKws2bN7FgwQIkJyejRYsW2Lt3L4KCggAAycnJRnOW5OTk4KWXXsLVq1fh5uaG5s2bY8+ePejbt6/tvsV9evZZPebMccC//w3s3w9ERtq7RERERFWPVR1dY2JiEBMTU+R7GzduNHo9Y8YMzJgxw5rDlBsvLyA6GlixAnjnHYYSIiIie+CFiv+ZOBHQaIB9+wDOgE9ERFT+GEr+p0EDoF8/eb5qlX3LQkREVBUxlBQwZYo8btoE3Lpl16IQERFVOQwlBXTrBrRoAWRkAOvX27s0REREVQtDSQEaDTB5sjx/910gN9e+5SEiIqpKGEoKGTYMqFkTuHQJ+Oore5eGiIio6mAoKcTdHRg7Vp6/8459y0JERFSVMJQUISYGcHAADh4Ezp2zd2mIiIiqBoaSIgQGAk8+Kc/ZWkJERFQ+GEqKkTc8+NNPgZs37VsWIiKiqoChpBidOgFt2gBZWcCHH9q7NERERJUfQ0kxNJr81pL33gPu3bNveYiIiCo7hpISDBkC1KkD/Pe/wM6d9i4NERFR5cZQUgIXF2DcOHm+cqV9y0JERFTZMZSU4oUXAEdH4Ngx4PRpe5eGiIio8mIoKYW/PzB4sDzn8GAiIqKyw1BihrwOr1u3An/+ad+yEBERVVYMJWZ4+GGgQwcgJwf44AN7l4aIiKhyYigxU15ryZo1Ek6IiIjIthhKzDRoEBAQAKSkANu327s0RERElQ9DiZmcnGQkDiDDgxXFvuUhIiKqbBhKLDBunMxdcuoU8K9/2bs0RERElQtDiQVq1waGDpXnnEyNiIjIthhKLJTX4fWLL4CrV+1bFiIiosqEocRCISFAly5yg741a+xdGiIiosqDocQKkyfL4wcfAFlZ9i0LERFRZcFQYoX+/YHAQODGDeCzz+xdGiIiosrB0d4FqIgcHYEJE4BXXgEmTZJOr7Vry1KnTv7zwuuqVwc0GnuXnoiISJ0YSqw0ZgywdClw/Tpw9qx5n3F0BHx88sNK/frAa68BwcFlWlQiIqIKgaHESjVrAr/9Bvz73xJMCi6pqabr0tKkc2xKiix5jh4Fvv8eqFbNft+FiIhIDRhK7oOXFxAaat622dmmweXVVyXUjBgB7NwJaNnDh4iIqjCGknLi4gLUrStLnqZNgUceAXbvBhYuBF5/3X7lIyIisjf+bW5H7drlz3Uybx6wZ49di0NERGRXDCV29txzQEyM3OBv2DDg4kV7l4iIiMg+GEpUYMUKoFMn4PZtYMAAID3d3iUiIiIqfwwlKuDsDGzfDvj7A+fPS+uJoti7VEREROWLoUQl/P3lJn9OTvL49tv2LhEREVH5YihRkfBw4J135PmsWUBcnH3LQ0REVJ4YSlRm3Dhg9GhArweGDAEuXbJ3iYiIiMoHQ4nKaDTAe+8B7dsDf/0FPPUUkJlp71IRERGVPYYSFXJ1BXbskPvjJCQAzz/Pjq9ERFT5MZSoVL16MiLHwQHYvDm/rwkREVFlxVCiYo8+CixbJs+nTwcOH7ZveYiIiMoSQ4nKTZ4sM73m5gJPPw1cuWLvEhEREZUNhhKV02iAtWuBkBC5u/DAgUBWlr1LRUREZHsMJRWAuzuwcydQsyZw6hQwYQI7vhIRUeXDUFJB1K8PbN0KaLXA+vXABx/Yu0RERES2xVBSgfTqBSxaJM8nTwZOnLBveYiIiGzJqlCyevVqBAcHw9XVFaGhoYiPjzfrc8eOHYOjoyNCQkKsOSwBePll6fCq0wGPPSajc+7etXepiIiI7p/FoWTbtm2YOnUqZs+ejTNnzqBz586IjIxEUlJSiZ+7ffs2RowYgR49elhdWJKOr+vXA+3aAX//Dbz0EvDggzILbHa2vUtHRERkPUdLP7B8+XJER0djzJgxAIDY2Fjs378fa9aswaK8awtFGDduHJ555hk4ODhg165dJR4jOzsb2QXOsGlpaQAAnU4HnU5naZGLlbcvW+6zPLi4AEeOAJs3a7BwoQP++EODiROBJUsUzJ6di2efVeDkVHbHr6j1Zm+sN+uw3izHOrMO6806JdWbpXWpURTzx3Hk5OTA3d0d27dvx5NPPmlYP2XKFCQkJOBwMbN7bdiwAatXr8aJEyewcOFC7Nq1CwkJCcUeZ968eZg/f77J+i1btsDd3d3c4lYJOp0G33wThO3bG+Ovv9wAAH5+6Rgy5AI6d/4vHBzsXMBC/v7bBTt2NEJYWDKaN79p7+IQEVEZyszMxDPPPIPbt2/D29u71O0taim5ceMGcnNz4evra7Te19cXKSkpRX7m4sWLmDlzJuLj4+HoaN7hZs2ahWnTphlep6WloV69eoiIiDDrS5lLp9MhLi4OvXr1glNZNi2Usf79gSVLgLVrc7FkiRYpKZ6IjQ3Fvn1tMXduLp58UoHWhl2ara2369eBnj0dkZioweHDDfD99/fw4IO2K5faVZbfW3ljvVmOdWYd1pt1Sqq3vCsd5rL48g0AaDQao9eKopisA4Dc3Fw888wzmD9/Pho3bmz2/l1cXODi4mKy3snJqUx+KGW13/Lk5CT9S8aPB1atAt5+G/j1Vw2GDnVE69bAG28Ajz8ufVJsd0zz6+2vv6RjbmKivL5zR4MRI5xw9Cjg7Gy7MlUEleH3Zg+sN8uxzqzDerNOUfVmaT1a9Pezj48PHBwcTFpFUlNTTVpPAODOnTv44YcfMHHiRDg6OsLR0RELFizA2bNn4ejoiIMHD1pUWCqdpycwaxZw6RIwdy7g5QWcPQs88QTQsSMQF1f+E6/dvg306SN3PPb1lTJUry4Twb3+evmWhYiI1MuiUOLs7IzQ0FDExcUZrY+Li0N4eLjJ9t7e3jh37hwSEhIMy/jx49GkSRMkJCSgQ4cO91d6Kla1asC8eRJOXnkFcHMDvv8eiIgAunaVjrLlIT0d6NtXAoiPD/Dtt0DPnsBHH8n7S5YA33xTPmUhIiJ1s7inwbRp0/DRRx9h/fr1SExMxIsvvoikpCSMHz8egPQHGTFihOxcq0WLFi2Mljp16sDV1RUtWrSAh4eHbb8NmahVC3jrLeD334EpU+RSyZEjcgfiYcMACy/3WSQzE+jXDzh+XFpG4uKA5s3lvYEDgXHjpNVm+HDpb0JERFWbxaEkKioKsbGxWLBgAUJCQnDkyBHs3bsXQUFBAIDk5ORS5yyh8ufnB8TGAr/9Jv1OHByALVuAtm2BH36w/fGysoAnnwQOHZJLSAcOyE0FC1q+HGjWDEhJAUaN4v18iIiqOqvGZMTExODy5cvIzs7G6dOn0aVLF8N7GzduxKFDh4r97Lx580ocDkxlq25dYM0aaS0JDJSQEh4ugcVWoSAnR2adPXAA8PAAvv4aaN/edDt3d7mfj4sLsHcv8M47tjk+ERFVTLz3TRUVHg6cOSOtGTod8OKL0hn2xo372++9e8DQocBXXwGurvLYqVPx27dsKVPlA8CMGdIZVq3OnQMWLpTLUkREZHsMJVVYzZrAjh0yRb2LiwSI1q2BYubAK1VuLjBiBPDll9J35R//kE61pYmJkUCUkwMMGQJkZFh3/LKUliYddufM4YghIqKywlBSxWk0Egr+9S+gSRPg2jWge3dg/nwJGebS64GxY4HPPgMcHYEvvpCRPuaWYf164IEHgAsXpEOu2sycCfz3v/J81SrpOExERLbFUEIApIXk9GnpcKrXy3DiHj2Aq1dL/6yiABMmABs2SAfarVtl1I0latUCPv1UAsq6dcDnn1vzLcrGkSPSDwcAmjaVFp2ZM+1bJiKiyoihhAw8PCRYfPKJTMJ2+LCElT17iv+Mokh/lPffl0Dx8ccy3NcaXbsCr74qz59/Hrh82br92NLdu8D/7j2JsWMlLGm1wPbtMtSZiIhsh6GETDz7LPDjjzJc+OZNmZ5+2jRpIShIUWT22JUr5fW6dcAzz9zfsefOBcLCZBbYZ56RjrP2tGABcPEiEBAgE721bAmMHi3vTZ/OYcxERLbEUEJFatRIWgKmTpXXK1bIiJ3//Cd/m4ULtVi8WJ6vWQM899z9H9fJSeZP8fYGTpyQvi328uOPcg8hQL5f9ery/I03pFXp5El1XWYiIqroGEqoWC4uEkZ275aROqdPS+vJ1q0a7NjRCG+84QBAtvnfhL42Ub8+sHatPH/zTZmArbzpdEB0tHT2HTxYRgfl8fOTqfsBeczKKv/yERFVRgwlVKp+/eSmfp07A3fuACNGOOKTT5oBkCns81pTbCkqSkKBosjlpJs3bX+MkixdKnOm1KxZ9KRu06fLaKE//uCkb0REtsJQQmapWxc4eFD6fGg00pFizpxcQ4tBWVi5UoYpX72aH1DKw4UL+ZeNYmPlzsaFubtLKw4gj7x3DxHR/WMoIbM5OspQ4ZMn72H27JN47TV9mR7Pw0OGF+dNxJY3LLcs6fUy2iY7G+jTR1ppijN8ONCmjUysZs++L0RElQVDCVmsTRugffs/odGU/bFCQmTUCyAjgM6dK9vjvf8+cPSoDInOG+ZcHK02f4r8998Hfv21bMtGRFTZMZSQ6k2eDDz2mLReDB1adveeSUrK78C6aBHwvxtfl6hbN+kEm5sr9+4hIiLrMZSQ6mk0Mqmbnx/wyy/SydTWFEVGEKWnyw0EY2LM/+ySJXJp65//lH43RERkHYYSqhBq186fhv7992UCs7Q02+1/82bg66+l/8pHH8mlGXM1aZI/JHr6dMvuGURERPkYSqjC6NEDWLw4v+WkVSvbzGGSmpo/rHnuXLm/jaXmzgWqVZNhxJ98cv9lKmzrVqBXL2DXLtvvm4hILRhKqEJ5+WW5J09wsMwR0q2bdIC9nwnMpkyReVBat5b9W8PHB5g9W57Png1kZFhfnoL0etnf0KHAN98ATz4pc7ikptpm/0REasJQQhVO584ymdvzz8vrFSuA0FCZcdZSu3dLK4RWK/fucXKyvlyTJslstNeu5Y/KuR8ZGcDTTwP/93/yuk8fuQvz558DzZrJdPy89w4RVSYMJVQheXkBH3wgdzD28wPOnwc6dpQb6Ol05u3j9m3ghRfk+UsvSbC5H66uMsMtIJ1fk5Ot39fVq0CXLsCXX0pQ2rhR+rx8/71ctrp5Exg2TEb+XL16f+UmIlILhhKq0Pr2BX7+WVoU7t2Tvh2dOsmsrKWZMUNaNRo2lEnhbGHwYAlHGRnAnDnW7eOHH4D27eWGgD4+MqJn5Eh5r21b4NQpCV9OTsBXX0mryUcfsdWEiCo+hhKq8GrVArZtkxE01avLSTskBFi1SvpkFOXQofyb/n30EeDmZpuyaDTA8uXyfP16ucxkie3b5fJUcjLQvLm0jDzyiPE2zs4SeM6cAR5+WEYhjR0rHWEvXbLN9yAisgeGEqoUNBrgmWdkxtdevaTj6+TJQEQEcOWK8baZmXISB2Qo76OP2rYsYWHSYqIoclnInBYMRQHeeEM+l5UlLUDHj0uH3uI0by7bLFsmoerbb4EWLeSeQRyWTEQVEUMJVSp16wL79wPvvZd/om7ZUobp5oWDefOA//xH7vK7eHHZlOOtt6RF45tvpC9ISe7elf4hr78ur6dOlQ643t6lH8fBQUYf/fSThKvMTPl8ly6c9p6IKh6GEqp0NBqZkfXsWenfcfs2MGIEMGiQBIS8kTFr1ph34rdGcLC01ADSWnLvXtHbpaTIsObPPpNZYT/4QEYTOThYdryGDaXvyZo1ct+e48flEtZbbxV/bCIitWEooUqrUSMgPh5480054X/5pVwW0etl3o9+/cr2+LNnS3+XxETpt1LY2bPSJ+Rf/wJq1AAOHMgf5mwNrVYuR/3yiwwfzs4GZs0COnSwvG8LEZE9MJRQpeboCLz6qnQYbd5c1tWqJf0uylr16jIaCJBLMwWnxf/HP2SU0JUrQOPGEky6dbPNcQMDgb17gU2bJOz8+CPQrp0Elm3b5MaDHKlDRGrEUEJVQps2MtR23ToZeVO7dvkcd/x4CR3XrwNLlmihKMDSpVo8+aQMG+7ZEzh5Ulp1bEmjkUtW588DTz0ll3A++AAYMkTufvzAA8DAgcDSpcDRo9KvhYjI3hztXQCi8uLqKjfyK09OTsDbbwP9+wMrV2px7Fg7HDsmHUZeeEFabO5nFtnS+PkBO3YA+/bJRHMnTsilnORkuZz15ZeynaOj9EEJC5OlY0eZnVajKbuyVWYnT0rg+/VX6SPUq5e9S0RUMTCUEJWxfv2Arl2BQ4c0OHbsAWi1Clau1GDChPI76ffpIwsgI3ROn5aAcvKkPKakSEvSDz/I/C4A4Osr4SQsTC7/ODrKcOXsbHm0ZHngAWDCBOtudlhR6PUymd3bb0vrU57evYGZM2XCO0f+H5eoRPxPhKiMaTQy4icsTIGj4z18/rkGjz1mv//03N1lgrbOneW1okg/kxMn8oPKmTPAn39K35d//MM2x333XZkW/+WXpT9NZWmFyc4GPv00v2UEkNavZ5+VUVQffQQsWgQcOSKjrOrVs295idSMoYSoHLRtC5w9ew+nTn2DiIie9i6OEY1G+pkEBUmfE0D6mJw5kx9SfvpJRve4ulq+ODvL3DG7d+cvHTtKOOnf3/Lhz2rx99/A++8D77wjLU0AUK2a9COaPBkICJB1ERHAmDHAsWNyiWzDBglnaqUoMr9OrVryu6WypdcDCQlS55mZcvsLd3d7l8p+GEqIysmDDwIXLuTYuxhmcXMDwsNlsYUXXpD7ES1bBnz8sQSdgQOlg++0aXJvH1tN9V/WkpKA2Fjgww+B9HRZV7cu8OKLEj4Kz33z9NNys8eoKLk81r8/MGWKTNzn4lLuxS/RzZsSqr74QsLi0qVS1srSqqUGigL8/ruEkG+/lfmFbt7Mf//rr4F//hOoU8d+ZbQnjr4honLRpIncb+iPP2QOlxo1gIsXJbAEBUmfi4L/c1abs2flkkyDBtJ5NT1dZgv++GM5yUybVvxkfA0aSEvJtGnyeuVKuYT122/lV/7S7N8v3+eLLySE5OZK0Bo1iqOz7tf16zIcf+xY+S00bCjhb/t2+c17eQGPPw7UrCnTF3TsWHVnZGYoIaJy5esLLFyY3+IQFCT/0547V/pbTJqknhsLKgoQFyeXYEJC5KaPublAjx4younsWWD4cPNGUDk7S0vRP/8pJ5/Tp2Wo+tatZf41SpSZKXXep4+MymraVG5qGRsrrSUffyy3Lfjvf+1bzookI0N+Hy+9JL+bOnXk0uhHHwGXL8vvpUsXYP58Cas3b8rv4sQJaVG9dElaKQ8ftvc3KX+8fENEduHpKZcGJkyQvxjfflv6sbz7LrB6tdwW4OWXgdatzd9nbq78VZ+ZabpkZBS9vqTtkpPlPkmAnKCfflrKdD99LR5/XPoQPPOMjNIZOhT47jsJAeV9Cev0aWn9yfurfNIkuTWBu7tccmrRIv+yU7t2Mry8U6fyLWNFkJ0tLRyHDsklmePHAZ3OeJtWrWReop49pZO5p6fpfho3lmDSv7889uolfZCGDSuXr6EKDCVEZFeOjnJiHjJErq+//bZcSvj8c1k6d3aAk1MbfPqpA7KySg4UOWXQZcfdXfqKvPiizN1iC/XqSRCZP19ug7B2rZzItm0DmjWzzTFKcu+e9GmZN0+e+/vLya93b+PtevSQVpMBA6Szc7duMmR83LiyL6OaZWXJLMyHD0sQOXFC1hUUGCihomdPoHt38/uI1K4twWbECLmU9uyz0nIye3bV6NvDUEJEqqDRyEmwRw85AS5dKkNo4+O1AAIt3p+bmwQKd3fAwyP/eeGluPc8PGR5+GG53GJrjo7AG2/I3Z2ffRb4+WegfXtpKRo1quxOQL/9Jie848fl9aBBMoqoVq2itw8Olm1Hj5aQOH68tGi9845ckqoK7t6VztmHDkkQOXlSWkcKqlNH/i27d5cg8uCD1v8burlJQJ05U0L6nDkSTN5/v2wnW1QDhhIiUp1WraQvw5tvAlu25OL8+V/Rpk1TeHk5FBsuCi6urhXnr8qePfP7psTFycn/22/ljs9eXrY7jqIA69cDU6dKJ11vbwlAzz5bel15eEjflzZt5F5SH3wgIeqLL2TW4MomM1MuWeWFkH/9y7QVzs9PQkjXrvLYtKltf3NaLbBkibTOTZok/3ZJSVLn1arZ7jhqw1BCRKpVrx4wbZoee/f+B337NoaTUwWd1KQUvr7SMXLxYvmrePNm6aPw1lvStyMw8P5OeNevyx2od+2S1126SOgLCjJ/HxqN/OXeqpX0hzl2TPqZ7NwpLTz2kpUlfX+uXZPlzz8lQNy7J32McnNLf573qNM54PTpR/Cf/zia9AkJCDAOIY0bl0/wjYmRf6eoKBlG/MgjcsuIQMsbDysEhhIiIhXQaoFZsyQwDBkiw6UHDpT3qleXMNCqlXT8bd1aOqGa0zF2zx5pfUlNlab/hQuB6dOtn7Sub18JTAMGAImJ0mlz7Vq5JGRLOTkyKV1e2Lh2zTh85C1//WXLo2oByHWsunXzA0jXrvd3OeZ+PfaYzAj8+OPSQtWxo9zSoDJObsdQQkSkIp06yeicuXOB+Hg58d+6JSelI0fyt9NqZfK5vJCStzzwgLyfleWACRO0+PBDed28ubTAWDKaqTiNG0u/iuHDZYbekSOln8nbb1t+f5+sLDnRnjmTv/z2m7TumMvFRb53QIC0Orm6SuhydDR+LO05kItr185iwoSWaNzYSVWXANu2lTp/7DGpry5dpN/JY4/Zu2S2xVBCRKQytWpJfw9AWgx+/VX6nRRcrl+XWXIvXJAOqHlq1gRatnTAhQtdkZIizSEvvgj83//JydpWvL3l0s38+TLxXWysdFD+/PPiO82mpUng+vHH/ACSmCiXT4ri5CQjgwICSl6qV7dNK4ZOp8fevVfQoEFLVQWSPIGBMox80CC5lPPEE/I7eeEFe5fMdhhKiIhUzNk5/9LN8OGyTlHk0sZPPxkHlV9/lcsZhw9rAXiibl0FGzdq0KNH2ZRNq5VQ0rq1XL45eFD6mfzjH9JiUTB85LWAFKVWLelE26aNtAg0bSotH7VqyTEoX7VqwN69Mgpq/Xrpc/L779IfqTLUFUMJEVEFo9FIC4K/v/HcIllZ0vLw44/3cPLkebz55kOoU6fsx5A+9ZRc0unfX06QISESnIoSGJgfQPKWunUrzmgpNXByktlhGzQAXntNhs9fviyj1XQ6aV3LzjbvseDzIUPkVgP2xFBCRFRJuLrKSb5FCwU+PpdQo8ZD5XbsFi1korWhQ4EDByRkNGliGkCKu7RDltFoZEK1+vWlI/MXX8hyP1q2ZCghIqJKomZNGdp8+bLMTFrUVOpkW8OGSUvTmDEyHNrZWTr+lvRY3HsNG9r72zCUEBGRDWk0MgsslZ9HH5Uh5JWBVd1iVq9ejeDgYLi6uiI0NBTx8fHFbnv06FF06tQJtWrVgpubG5o2bYoVK1ZYXWAiIiKqnCxuKdm2bRumTp2K1atXo1OnTvjggw8QGRmJ8+fPI7CIKeY8PDwwceJEtGrVCh4eHjh69CjGjRsHDw8PPP/88zb5EkRERFTxWRxKli9fjujoaIwZMwYAEBsbi/3792PNmjVYtGiRyfZt2rRBmzZtDK/r16+PL7/8EvHx8cWGkuzsbGQXuNtRWloaAECn00FXeO7f+5C3L1vusypgvVmH9WYd1pvlWGfWYb1Zp6R6s7QuNYpS3MAtUzk5OXB3d8f27dvx5JNPGtZPmTIFCQkJOHz4cKn7OHPmDCIjI7Fw4UJDsCls3rx5mD9/vsn6LVu2wN3d3dziEhERkR1lZmbimWeewe3bt+Ht7V3q9ha1lNy4cQO5ubnw9fU1Wu/r64uUlJQSP1u3bl1cv34d9+7dw7x584oNJAAwa9YsTJs2zfA6LS0N9erVQ0REhFlfylw6nQ5xcXHo1asXnCr7/aBtiPVmHdabdVhvlmOdWYf1Zp2S6i3vSoe5rBp9oyk0y42iKCbrCouPj0d6ejpOnjyJmTNnomHDhhg6dGiR27q4uMDFxcVkvZOTU5n8UMpqv5Ud6806rDfrsN4sxzqzDuvNOkXVm6X1aFEo8fHxgYODg0mrSGpqqknrSWHB/xsj1rJlS/z555+YN29esaGEiIiIqh6LhgQ7OzsjNDQUcXFxRuvj4uIQHh5u9n4URTHqyEpERERk8eWbadOmYfjw4WjXrh3CwsKwdu1aJCUlYfz48QCkP8jVq1fx8ccfAwDee+89BAYGomnTpgBk3pKlS5di0qRJNvwaREREVNFZHEqioqJw8+ZNLFiwAMnJyWjRogX27t2LoKAgAEBycjKSkpIM2+v1esyaNQuXLl2Co6MjHnzwQbz11lsYN26c7b4FERERVXhWdXSNiYlBTExMke9t3LjR6PWkSZPYKkJERESlsmqaeSIiIiJbYyghIiIiVWAoISIiIlWwqk9JecubCd/SmeFKo9PpkJmZibS0NE6UYwHWm3VYb9ZhvVmOdWYd1pt1Sqq3vPO2uXe0qRCh5M6dOwCAevXq2bkkREREZKk7d+6gWrVqpW5n0Q357EWv1+PatWvw8vIqdTp7S+TdU+fKlSs2vadOZcd6sw7rzTqsN8uxzqzDerNOSfWmKAru3LmDgIAAaLWl9xipEC0lWq0WdevWLbP9e3t78wdoBdabdVhv1mG9WY51Zh3Wm3WKqzdzWkjysKMrERERqQJDCREREalClQ4lLi4umDt3LlxcXOxdlAqF9WYd1pt1WG+WY51Zh/VmHVvWW4Xo6EpERESVX5VuKSEiIiL1YCghIiIiVWAoISIiIlVgKCEiIiJVqNKhZPXq1QgODoarqytCQ0MRHx9v7yKp2rx586DRaIwWPz8/exdLdY4cOYJ+/fohICAAGo0Gu3btMnpfURTMmzcPAQEBcHNzQ9euXfHLL7/Yp7AqUVqdjRo1yuS317FjR/sUViUWLVqE9u3bw8vLC3Xq1MGAAQNw4cIFo234WzNlTr3x92ZqzZo1aNWqlWGCtLCwMHz99deG9231W6uyoWTbtm2YOnUqZs+ejTNnzqBz586IjIxEUlKSvYumas2bN0dycrJhOXfunL2LpDoZGRlo3bo13n333SLfX7JkCZYvX453330Xp06dgp+fH3r16mW4x1NVVFqdAUCfPn2Mfnt79+4txxKqz+HDhzFhwgScPHkScXFxuHfvHiIiIpCRkWHYhr81U+bUG8DfW2F169bFW2+9hR9++AE//PADunfvjv79+xuCh81+a0oV9fDDDyvjx483Wte0aVNl5syZdiqR+s2dO1dp3bq1vYtRoQBQdu7caXit1+sVPz8/5a233jKsy8rKUqpVq6a8//77diih+hSuM0VRlJEjRyr9+/e3S3kqitTUVAWAcvjwYUVR+FszV+F6UxT+3sxVo0YN5aOPPrLpb61KtpTk5OTg9OnTiIiIMFofERGB48eP26lUFcPFixcREBCA4OBgDBkyBL///ru9i1ShXLp0CSkpKUa/PRcXFzz66KP87ZXi0KFDqFOnDho3boyxY8ciNTXV3kVSldu3bwMAatasCYC/NXMVrrc8/L0VLzc3F1u3bkVGRgbCwsJs+lurkqHkxo0byM3Nha+vr9F6X19fpKSk2KlU6tehQwd8/PHH2L9/Pz788EOkpKQgPDwcN2/etHfRKoy83xd/e5aJjIzE5s2bcfDgQSxbtgynTp1C9+7dkZ2dbe+iqYKiKJg2bRoeeeQRtGjRAgB/a+Yoqt4A/t6Kc+7cOXh6esLFxQXjx4/Hzp070axZM5v+1irEXYLLikajMXqtKIrJOsoXGRlpeN6yZUuEhYXhwQcfxKZNmzBt2jQ7lqzi4W/PMlFRUYbnLVq0QLt27RAUFIQ9e/bgqaeesmPJ1GHixIn46aefcPToUZP3+FsrXnH1xt9b0Zo0aYKEhATcunULO3bswMiRI3H48GHD+7b4rVXJlhIfHx84ODiYJLjU1FSTpEfF8/DwQMuWLXHx4kV7F6XCyButxN/e/fH390dQUBB/ewAmTZqE3bt347vvvkPdunUN6/lbK1lx9VYU/t6Es7MzGjZsiHbt2mHRokVo3bo1Vq5cadPfWpUMJc7OzggNDUVcXJzR+ri4OISHh9upVBVPdnY2EhMT4e/vb++iVBjBwcHw8/Mz+u3l5OTg8OHD/O1Z4ObNm7hy5UqV/u0pioKJEyfiyy+/xMGDBxEcHGz0Pn9rRSut3orC31vRFEVBdna2bX9rNuqEW+Fs3bpVcXJyUtatW6ecP39emTp1quLh4aFcvnzZ3kVTrenTpyuHDh1Sfv/9d+XkyZPK448/rnh5ebHOCrlz545y5swZ5cyZMwoAZfny5cqZM2eUP/74Q1EURXnrrbeUatWqKV9++aVy7tw5ZejQoYq/v7+SlpZm55LbT0l1dufOHWX69OnK8ePHlUuXLinfffedEhYWpjzwwANVus5eeOEFpVq1asqhQ4eU5ORkw5KZmWnYhr81U6XVG39vRZs1a5Zy5MgR5dKlS8pPP/2kvPrqq4pWq1UOHDigKIrtfmtVNpQoiqK89957SlBQkOLs7Ky0bdvWaEgYmYqKilL8/f0VJycnJSAgQHnqqaeUX375xd7FUp3vvvtOAWCyjBw5UlEUGao5d+5cxc/PT3FxcVG6dOminDt3zr6FtrOS6iwzM1OJiIhQateurTg5OSmBgYHKyJEjlaSkJHsX266Kqi8AyoYNGwzb8LdmqrR64++taKNHjzacL2vXrq306NHDEEgUxXa/NY2iKIqVLTdERERENlMl+5QQERGR+jCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBBRhaTRaLBr1y57F4OIbIihhIgsNmrUKGg0GpOlT58+9i4aEVVgjvYuABFVTH369MGGDRuM1rm4uNipNERUGbClhIis4uLiAj8/P6OlRo0aAOTSypo1axAZGQk3NzcEBwdj+/btRp8/d+4cunfvDjc3N9SqVQvPP/880tPTjbZZv349mjdvDhcXF/j7+2PixIlG79+4cQNPPvkk3N3d0ahRI+zevbtsvzQRlSmGEiIqE3PmzMHAgQNx9uxZPPvssxg6dCgSExMBAJmZmejTpw9q1KiBU6dOYfv27fjmm2+MQseaNWswYcIEPP/88zh37hx2796Nhg0bGh1j/vz5GDx4MH766Sf07dsXw4YNw19//VWu35OIbMh2NzYmoqpi5MiRioODg+Lh4WG0LFiwQFEUuT38+PHjjT7ToUMH5YUXXlAURVHWrl2r1KhRQ0lPTze8v2fPHkWr1SopKSmKoihKQECAMnv27GLLAEB57bXXDK/T09MVjUajfP311zb7nkRUvtinhIis0q1bN6xZs8ZoXc2aNQ3Pw8LCjN4LCwtDQkICACAxMRGtW7eGh4eH4f1OnTpBr9fjwoUL0Gg0uHbtGnr06FFiGVq1amV47uHhAS8vL6Smplr7lYjIzhhKiMgqHh4eJpdTSqPRaAAAiqIYnhe1jZubm1n7c3JyMvmsXq+3qExEpB7sU0JEZeLkyZMmr5s2bQoAaNasGRISEpCRkWF4/9ixY9BqtWjcuDG8vLxQv359fPvtt+VaZiKyL7aUEJFVsrOzkZKSYrTO0dERPj4+AIDt27ejXbt2eOSRR7B582Z8//33WLduHQBg2LBhmDt3LkaOHIl58+bh+vXrmDRpEoYPHw5fX18AwLx58zB+/HjUqVMHkZGRuHPnDo4dO4ZJkyaV7xclonLDUEJEVtm3bx/8/f2N1jVp0gS//vorABkZs3XrVsTExMDPzw+bN29Gs2bNAADu7u7Yv38/pkyZgvbt28Pd3R0DBw7E8uXLDfsaOXIksrKysGLFCrz00kvw8fHBoEGDyu8LElG50yiKoti7EERUuWg0GuzcuRMDBgywd1GIqAJhnxIiIiJSBYYSIiIiUgX2KSEim+NVYSKyBltKiIiISBUYSoiIiEgVGEqIiIhIFRhKiIiISBUYSoiIiEgVGEqIiIhIFRhKiIiISBUYSoiIiEgV/h+LHfW+cPontAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(30), test_accuracy, 'r-', label='Validation accuracy')\n",
    "plt.plot(np.arange(30), test_loss, 'b-', label='Validation loss')\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa42855",
   "metadata": {},
   "source": [
    "### Performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "246cc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_performance(dataloader, model):\n",
    "    test_accuracy = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            correct += (preds.argmax(1) == y).type(torch.float32).sum().item()\n",
    "    return correct / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c13e9632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8822"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_test_performance(test_loader, classif_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df76ea",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API\n",
    "\n",
    "For this example we use the California Housing dataset. After creating a training, validation, and test set, we must normalize the data and organize them into dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3999407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25dd2e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 8), (3870, 8), (5160, 8))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdde54a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.68120000e+00,  2.50000000e+01,  4.19220056e+00,  1.02228412e+00,\n",
       "        1.39200000e+03,  3.87743733e+00,  3.60600000e+01, -1.19010000e+02])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04183e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, std_devs = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "means.shape, std_devs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b396fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ((x_train - means) / std_devs).astype(np.float32)\n",
    "x_valid = ((x_valid - means) / std_devs).astype(np.float32)\n",
    "x_test = ((x_test - means) / std_devs).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "411e407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a75419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = TensorDataset(torch.FloatTensor(x_train),\n",
    "                           torch.FloatTensor(y_train).unsqueeze(-1))\n",
    "valid_dset = TensorDataset(torch.FloatTensor(x_valid),\n",
    "                           torch.FloatTensor(y_valid).unsqueeze(-1))\n",
    "test_dset = TensorDataset(torch.FloatTensor(x_test),\n",
    "                          torch.FloatTensor(y_test).unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e522ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3852c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential_model = nn.Sequential(\n",
    "            nn.Linear(in_features=8, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sequential_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78749533",
   "metadata": {},
   "source": [
    "### Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52aa1245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model = RegressionModel()\n",
    "regression_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7727e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = regression_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d8c444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(dataloader, model, loss_fn, optimizer):\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x)\n",
    "        batch_loss = loss_fn(preds, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 100 == 0:\n",
    "            print(f'Train Loss: {batch_loss.item():>.5}. Batch: [{batch}/{num_batches}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96cbfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression(dataloader, model, loss_fn):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            total_loss += loss_fn(preds, y).item()\n",
    "        print(f'Validation Loss: {total_loss/num_batches:>.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd0006c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "regression_optim = optim.Adam(regression_model.parameters(), lr=1e-3, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3a1855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Epoch 1 -----\n",
      "\n",
      "Train Loss: 4.6812. Batch: [0/363]\n",
      "Train Loss: 0.61528. Batch: [100/363]\n",
      "Train Loss: 0.3824. Batch: [200/363]\n",
      "Train Loss: 0.35226. Batch: [300/363]\n",
      "Validation Loss: 0.493\n",
      "\n",
      " ----- Epoch 2 -----\n",
      "\n",
      "Train Loss: 0.28571. Batch: [0/363]\n",
      "Train Loss: 0.39985. Batch: [100/363]\n",
      "Train Loss: 0.356. Batch: [200/363]\n",
      "Train Loss: 0.60781. Batch: [300/363]\n",
      "Validation Loss: 2.5737\n",
      "\n",
      " ----- Epoch 3 -----\n",
      "\n",
      "Train Loss: 0.50656. Batch: [0/363]\n",
      "Train Loss: 0.36145. Batch: [100/363]\n",
      "Train Loss: 0.27962. Batch: [200/363]\n",
      "Train Loss: 0.23393. Batch: [300/363]\n",
      "Validation Loss: 2.3216\n",
      "\n",
      " ----- Epoch 4 -----\n",
      "\n",
      "Train Loss: 0.52253. Batch: [0/363]\n",
      "Train Loss: 0.18368. Batch: [100/363]\n",
      "Train Loss: 0.33468. Batch: [200/363]\n",
      "Train Loss: 0.27719. Batch: [300/363]\n",
      "Validation Loss: 1.373\n",
      "\n",
      " ----- Epoch 5 -----\n",
      "\n",
      "Train Loss: 0.52883. Batch: [0/363]\n",
      "Train Loss: 0.83932. Batch: [100/363]\n",
      "Train Loss: 0.29432. Batch: [200/363]\n",
      "Train Loss: 0.37331. Batch: [300/363]\n",
      "Validation Loss: 1.9102\n",
      "\n",
      " ----- Epoch 6 -----\n",
      "\n",
      "Train Loss: 0.13499. Batch: [0/363]\n",
      "Train Loss: 0.081687. Batch: [100/363]\n",
      "Train Loss: 0.23685. Batch: [200/363]\n",
      "Train Loss: 0.16314. Batch: [300/363]\n",
      "Validation Loss: 0.72452\n",
      "\n",
      " ----- Epoch 7 -----\n",
      "\n",
      "Train Loss: 0.30925. Batch: [0/363]\n",
      "Train Loss: 0.55779. Batch: [100/363]\n",
      "Train Loss: 0.19397. Batch: [200/363]\n",
      "Train Loss: 0.34311. Batch: [300/363]\n",
      "Validation Loss: 0.46304\n",
      "\n",
      " ----- Epoch 8 -----\n",
      "\n",
      "Train Loss: 0.30535. Batch: [0/363]\n",
      "Train Loss: 0.10203. Batch: [100/363]\n",
      "Train Loss: 0.1254. Batch: [200/363]\n",
      "Train Loss: 0.2783. Batch: [300/363]\n",
      "Validation Loss: 0.64867\n",
      "\n",
      " ----- Epoch 9 -----\n",
      "\n",
      "Train Loss: 0.39068. Batch: [0/363]\n",
      "Train Loss: 0.20099. Batch: [100/363]\n",
      "Train Loss: 0.23152. Batch: [200/363]\n",
      "Train Loss: 0.33051. Batch: [300/363]\n",
      "Validation Loss: 0.29063\n",
      "\n",
      " ----- Epoch 10 -----\n",
      "\n",
      "Train Loss: 0.18729. Batch: [0/363]\n",
      "Train Loss: 0.48359. Batch: [100/363]\n",
      "Train Loss: 0.24162. Batch: [200/363]\n",
      "Train Loss: 0.5963. Batch: [300/363]\n",
      "Validation Loss: 0.49567\n",
      "\n",
      " ----- Epoch 11 -----\n",
      "\n",
      "Train Loss: 0.25267. Batch: [0/363]\n",
      "Train Loss: 0.39409. Batch: [100/363]\n",
      "Train Loss: 0.15267. Batch: [200/363]\n",
      "Train Loss: 0.22713. Batch: [300/363]\n",
      "Validation Loss: 0.72671\n",
      "\n",
      " ----- Epoch 12 -----\n",
      "\n",
      "Train Loss: 0.30158. Batch: [0/363]\n",
      "Train Loss: 0.12772. Batch: [100/363]\n",
      "Train Loss: 0.4285. Batch: [200/363]\n",
      "Train Loss: 0.32637. Batch: [300/363]\n",
      "Validation Loss: 0.51553\n",
      "\n",
      " ----- Epoch 13 -----\n",
      "\n",
      "Train Loss: 0.64185. Batch: [0/363]\n",
      "Train Loss: 0.45136. Batch: [100/363]\n",
      "Train Loss: 0.23458. Batch: [200/363]\n",
      "Train Loss: 0.35649. Batch: [300/363]\n",
      "Validation Loss: 0.30143\n",
      "\n",
      " ----- Epoch 14 -----\n",
      "\n",
      "Train Loss: 0.16264. Batch: [0/363]\n",
      "Train Loss: 0.37426. Batch: [100/363]\n",
      "Train Loss: 0.26841. Batch: [200/363]\n",
      "Train Loss: 0.18242. Batch: [300/363]\n",
      "Validation Loss: 0.38011\n",
      "\n",
      " ----- Epoch 15 -----\n",
      "\n",
      "Train Loss: 0.38767. Batch: [0/363]\n",
      "Train Loss: 0.22929. Batch: [100/363]\n",
      "Train Loss: 0.34522. Batch: [200/363]\n",
      "Train Loss: 0.22891. Batch: [300/363]\n",
      "Validation Loss: 0.30782\n",
      "\n",
      " ----- Epoch 16 -----\n",
      "\n",
      "Train Loss: 0.49802. Batch: [0/363]\n",
      "Train Loss: 0.14462. Batch: [100/363]\n",
      "Train Loss: 0.29684. Batch: [200/363]\n",
      "Train Loss: 0.2084. Batch: [300/363]\n",
      "Validation Loss: 0.3064\n",
      "\n",
      " ----- Epoch 17 -----\n",
      "\n",
      "Train Loss: 0.31996. Batch: [0/363]\n",
      "Train Loss: 0.14582. Batch: [100/363]\n",
      "Train Loss: 0.30196. Batch: [200/363]\n",
      "Train Loss: 0.38262. Batch: [300/363]\n",
      "Validation Loss: 0.55673\n",
      "\n",
      " ----- Epoch 18 -----\n",
      "\n",
      "Train Loss: 0.2554. Batch: [0/363]\n",
      "Train Loss: 0.30261. Batch: [100/363]\n",
      "Train Loss: 0.3926. Batch: [200/363]\n",
      "Train Loss: 0.47087. Batch: [300/363]\n",
      "Validation Loss: 0.34018\n",
      "\n",
      " ----- Epoch 19 -----\n",
      "\n",
      "Train Loss: 0.21644. Batch: [0/363]\n",
      "Train Loss: 0.18343. Batch: [100/363]\n",
      "Train Loss: 0.37635. Batch: [200/363]\n",
      "Train Loss: 0.55241. Batch: [300/363]\n",
      "Validation Loss: 0.55223\n",
      "\n",
      " ----- Epoch 20 -----\n",
      "\n",
      "Train Loss: 0.16897. Batch: [0/363]\n",
      "Train Loss: 0.56318. Batch: [100/363]\n",
      "Train Loss: 0.22709. Batch: [200/363]\n",
      "Train Loss: 0.18022. Batch: [300/363]\n",
      "Validation Loss: 0.29974\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f'\\n ----- Epoch {epoch+1} -----\\n')\n",
    "    train_regression(train_loader, regression_model, loss_fn, regression_optim)\n",
    "    eval_regression(valid_loader, regression_model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c488a27",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d41f6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Linear(in_features=8, out_features=30)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layer2 = nn.Linear(in_features=30, out_features=30)\n",
    "        self.output_layer = nn.Linear(in_features=38, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.relu(self.hidden_layer1(x))\n",
    "        z = self.relu(self.hidden_layer2(z))\n",
    "        w = torch.cat((x, z), dim=-1)\n",
    "        return self.output_layer(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d3a2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "widedeep = WideAndDeep()\n",
    "widedeep.apply(init_weights)\n",
    "widedeep = widedeep.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90428cb",
   "metadata": {},
   "source": [
    "Note that we need to create another optimizer, as the existing one has been trained on a different architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cf1cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_optim = optim.Adam(widedeep.parameters(), lr=1e-3, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "445a9987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8.6954. Batch: [0/363]\n",
      "Train Loss: 1.3159. Batch: [100/363]\n",
      "Train Loss: 0.85891. Batch: [200/363]\n",
      "Train Loss: 1.1598. Batch: [300/363]\n",
      "Validation Loss: 0.90985\n",
      "Train Loss: 0.59334. Batch: [0/363]\n",
      "Train Loss: 0.59671. Batch: [100/363]\n",
      "Train Loss: 0.54503. Batch: [200/363]\n",
      "Train Loss: 0.30858. Batch: [300/363]\n",
      "Validation Loss: 1.5062\n",
      "Train Loss: 0.47393. Batch: [0/363]\n",
      "Train Loss: 0.44183. Batch: [100/363]\n",
      "Train Loss: 0.48225. Batch: [200/363]\n",
      "Train Loss: 0.54218. Batch: [300/363]\n",
      "Validation Loss: 0.39961\n",
      "Train Loss: 0.16247. Batch: [0/363]\n",
      "Train Loss: 0.40491. Batch: [100/363]\n",
      "Train Loss: 0.11579. Batch: [200/363]\n",
      "Train Loss: 0.65929. Batch: [300/363]\n",
      "Validation Loss: 0.36242\n",
      "Train Loss: 0.47726. Batch: [0/363]\n",
      "Train Loss: 0.44288. Batch: [100/363]\n",
      "Train Loss: 1.3181. Batch: [200/363]\n",
      "Train Loss: 0.40701. Batch: [300/363]\n",
      "Validation Loss: 1.0855\n",
      "Train Loss: 0.16801. Batch: [0/363]\n",
      "Train Loss: 0.27146. Batch: [100/363]\n",
      "Train Loss: 0.38227. Batch: [200/363]\n",
      "Train Loss: 0.19793. Batch: [300/363]\n",
      "Validation Loss: 1.1907\n",
      "Train Loss: 0.16918. Batch: [0/363]\n",
      "Train Loss: 0.28273. Batch: [100/363]\n",
      "Train Loss: 0.2008. Batch: [200/363]\n",
      "Train Loss: 0.14634. Batch: [300/363]\n",
      "Validation Loss: 1.4352\n",
      "Train Loss: 0.25083. Batch: [0/363]\n",
      "Train Loss: 0.17263. Batch: [100/363]\n",
      "Train Loss: 0.25148. Batch: [200/363]\n",
      "Train Loss: 0.43997. Batch: [300/363]\n",
      "Validation Loss: 1.7806\n",
      "Train Loss: 0.56756. Batch: [0/363]\n",
      "Train Loss: 0.20037. Batch: [100/363]\n",
      "Train Loss: 0.60475. Batch: [200/363]\n",
      "Train Loss: 0.38334. Batch: [300/363]\n",
      "Validation Loss: 1.4081\n",
      "Train Loss: 0.29943. Batch: [0/363]\n",
      "Train Loss: 0.25237. Batch: [100/363]\n",
      "Train Loss: 0.28485. Batch: [200/363]\n",
      "Train Loss: 0.4609. Batch: [300/363]\n",
      "Validation Loss: 0.53373\n",
      "Train Loss: 0.31834. Batch: [0/363]\n",
      "Train Loss: 0.46301. Batch: [100/363]\n",
      "Train Loss: 0.23977. Batch: [200/363]\n",
      "Train Loss: 0.43162. Batch: [300/363]\n",
      "Validation Loss: 0.4611\n",
      "Train Loss: 0.30656. Batch: [0/363]\n",
      "Train Loss: 0.26957. Batch: [100/363]\n",
      "Train Loss: 0.13422. Batch: [200/363]\n",
      "Train Loss: 0.32556. Batch: [300/363]\n",
      "Validation Loss: 0.32731\n",
      "Train Loss: 0.24813. Batch: [0/363]\n",
      "Train Loss: 0.1722. Batch: [100/363]\n",
      "Train Loss: 0.32993. Batch: [200/363]\n",
      "Train Loss: 0.11414. Batch: [300/363]\n",
      "Validation Loss: 0.3615\n",
      "Train Loss: 0.34873. Batch: [0/363]\n",
      "Train Loss: 0.19259. Batch: [100/363]\n",
      "Train Loss: 0.16873. Batch: [200/363]\n",
      "Train Loss: 0.32706. Batch: [300/363]\n",
      "Validation Loss: 0.29496\n",
      "Train Loss: 0.46982. Batch: [0/363]\n",
      "Train Loss: 0.18283. Batch: [100/363]\n",
      "Train Loss: 0.18533. Batch: [200/363]\n",
      "Train Loss: 0.39214. Batch: [300/363]\n",
      "Validation Loss: 0.35703\n",
      "Train Loss: 0.10816. Batch: [0/363]\n",
      "Train Loss: 0.32958. Batch: [100/363]\n",
      "Train Loss: 0.20621. Batch: [200/363]\n",
      "Train Loss: 0.41879. Batch: [300/363]\n",
      "Validation Loss: 0.70373\n",
      "Train Loss: 0.282. Batch: [0/363]\n",
      "Train Loss: 0.38749. Batch: [100/363]\n",
      "Train Loss: 0.78639. Batch: [200/363]\n",
      "Train Loss: 0.16652. Batch: [300/363]\n",
      "Validation Loss: 1.6019\n",
      "Train Loss: 3.4877. Batch: [0/363]\n",
      "Train Loss: 0.25874. Batch: [100/363]\n",
      "Train Loss: 0.32196. Batch: [200/363]\n",
      "Train Loss: 0.43758. Batch: [300/363]\n",
      "Validation Loss: 0.54181\n",
      "Train Loss: 0.33774. Batch: [0/363]\n",
      "Train Loss: 0.2818. Batch: [100/363]\n",
      "Train Loss: 0.27182. Batch: [200/363]\n",
      "Train Loss: 0.22847. Batch: [300/363]\n",
      "Validation Loss: 2.6879\n",
      "Train Loss: 0.26448. Batch: [0/363]\n",
      "Train Loss: 0.20872. Batch: [100/363]\n",
      "Train Loss: 0.25489. Batch: [200/363]\n",
      "Train Loss: 0.19594. Batch: [300/363]\n",
      "Validation Loss: 2.7139\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    train_regression(train_loader, widedeep, loss_fn, wnd_optim)\n",
    "    eval_regression(valid_loader, widedeep, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8c43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
