{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfe6779",
   "metadata": {},
   "source": [
    "# Chapter 10\n",
    "\n",
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8601b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76b9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data'\n",
    "full_train_dset = FashionMNIST(root=root_dir,\n",
    "                               train=True,\n",
    "                               download=True,\n",
    "                               transform=ToTensor())\n",
    "test_dset = FashionMNIST(root=root_dir,\n",
    "                         train=False,\n",
    "                         download=True,\n",
    "                         transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30ae606",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "if torch.cuda.device_count() == 2:\n",
    "    torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4c46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = Subset(full_train_dset, indices=range(55000))\n",
    "valid_dset = Subset(full_train_dset, indices=range(55000, 60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39bf7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dset), len(valid_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f761d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # Default batch size on keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef43a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5f4d3",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "In Geron's book the data are normalized by dividing by 255. The `ToTensor()` transform added to the Dataset definition takes care of this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c94788",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, tgt = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788b4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6fe9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02309bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential_model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=784, out_features=300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=300, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features=10))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sequential_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c057db0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model = MyModel()\n",
    "classif_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5596b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0025, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22176dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0172, -0.0012,  0.0147, -0.0222,  0.0215, -0.0214,  0.0159,  0.0212,\n",
       "         0.0188, -0.0332], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].weight[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce2bc7",
   "metadata": {},
   "source": [
    "## Weight initialization\n",
    "\n",
    "In Keras weights in a dense layer are, [by default](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense), initialized with a Glorot Uniform initialization.\n",
    "\n",
    "In Pytorch weights in a linear layer are, [by default](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) initialized with a uniform distribution with  U(âˆ’k,k) where k=1/in_features. This is essentially a LeCun uniform initialization. Note that in PyTorch, Glorot initialization is called Xavier initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9437ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf40d666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19df074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cecb27f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0434,  0.0522,  0.0365, -0.0370, -0.0265,  0.0726,  0.0289,  0.0270,\n",
       "        -0.0580, -0.0119], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].weight[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f506245",
   "metadata": {},
   "source": [
    "Both the bias and the weight look different. We assume that we are using the same initialization approach as Keras.\n",
    "\n",
    "The Keras model has a final softmax activation. If we use PyTorch cross-entropy loss, the softmax is fused in the loss, so we don't need to include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74120b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d87bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b844b7f",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "The example in Geron's book uses the \"sgd\" optimizer, which I suspect corresponds to the [default settings](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/SGD), i.e., lr = 0.01 and momentum = 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7487429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_optim = optim.SGD(classif_model.parameters(), lr=0.01, momentum=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e26dc5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x)\n",
    "        batch_loss = loss_fn(preds, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 250 == 0:\n",
    "            print(f'Train loss: {batch_loss.item():>.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67df4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            total_loss += loss_fn(preds, y).item()\n",
    "            correct += (preds.argmax(1) == y).type(torch.float).sum().item()\n",
    "    avg_batch_loss = total_loss / num_batches\n",
    "    accuracy = correct / num_obs\n",
    "    print('Validation:')\n",
    "    print(f'\\nAverage loss: {avg_batch_loss:>.5} - Accuracy: {accuracy:>.3}')\n",
    "    return avg_batch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffd85440",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aef7cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 1 -----\n",
      "\n",
      "Train loss: 2.3564\n",
      "Train loss: 0.78182\n",
      "Train loss: 0.7641\n",
      "Train loss: 0.66306\n",
      "Train loss: 0.78993\n",
      "Train loss: 0.5127\n",
      "Train loss: 0.42563\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.50528 - Accuracy: 0.823\n",
      "\n",
      "----- Epoch: 2 -----\n",
      "\n",
      "Train loss: 0.48282\n",
      "Train loss: 0.31914\n",
      "Train loss: 0.50171\n",
      "Train loss: 0.59217\n",
      "Train loss: 0.23079\n",
      "Train loss: 0.69483\n",
      "Train loss: 0.3701\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.47227 - Accuracy: 0.835\n",
      "\n",
      "----- Epoch: 3 -----\n",
      "\n",
      "Train loss: 0.2188\n",
      "Train loss: 0.4403\n",
      "Train loss: 0.38261\n",
      "Train loss: 0.44017\n",
      "Train loss: 0.89349\n",
      "Train loss: 0.48471\n",
      "Train loss: 0.39363\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.4271 - Accuracy: 0.848\n",
      "\n",
      "----- Epoch: 4 -----\n",
      "\n",
      "Train loss: 0.4441\n",
      "Train loss: 0.34227\n",
      "Train loss: 0.29001\n",
      "Train loss: 0.35759\n",
      "Train loss: 0.60983\n",
      "Train loss: 0.68696\n",
      "Train loss: 0.39053\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.40234 - Accuracy: 0.858\n",
      "\n",
      "----- Epoch: 5 -----\n",
      "\n",
      "Train loss: 0.67423\n",
      "Train loss: 0.51525\n",
      "Train loss: 0.14682\n",
      "Train loss: 0.31169\n",
      "Train loss: 0.30618\n",
      "Train loss: 0.2535\n",
      "Train loss: 0.3592\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.40496 - Accuracy: 0.859\n",
      "\n",
      "----- Epoch: 6 -----\n",
      "\n",
      "Train loss: 0.4726\n",
      "Train loss: 0.42249\n",
      "Train loss: 0.23039\n",
      "Train loss: 0.24503\n",
      "Train loss: 0.36028\n",
      "Train loss: 0.33082\n",
      "Train loss: 0.43162\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.38266 - Accuracy: 0.862\n",
      "\n",
      "----- Epoch: 7 -----\n",
      "\n",
      "Train loss: 0.23392\n",
      "Train loss: 0.43364\n",
      "Train loss: 0.32125\n",
      "Train loss: 0.41345\n",
      "Train loss: 0.35469\n",
      "Train loss: 0.54036\n",
      "Train loss: 0.39586\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.39129 - Accuracy: 0.863\n",
      "\n",
      "----- Epoch: 8 -----\n",
      "\n",
      "Train loss: 0.14673\n",
      "Train loss: 0.40252\n",
      "Train loss: 0.55578\n",
      "Train loss: 0.26917\n",
      "Train loss: 0.24059\n",
      "Train loss: 0.59532\n",
      "Train loss: 0.23437\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.35315 - Accuracy: 0.872\n",
      "\n",
      "----- Epoch: 9 -----\n",
      "\n",
      "Train loss: 0.39361\n",
      "Train loss: 0.39648\n",
      "Train loss: 0.34082\n",
      "Train loss: 0.18236\n",
      "Train loss: 0.26833\n",
      "Train loss: 0.19812\n",
      "Train loss: 0.26873\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.35524 - Accuracy: 0.871\n",
      "\n",
      "----- Epoch: 10 -----\n",
      "\n",
      "Train loss: 0.35538\n",
      "Train loss: 0.36151\n",
      "Train loss: 0.25045\n",
      "Train loss: 0.48182\n",
      "Train loss: 0.45314\n",
      "Train loss: 0.20641\n",
      "Train loss: 0.39638\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.35468 - Accuracy: 0.874\n",
      "\n",
      "----- Epoch: 11 -----\n",
      "\n",
      "Train loss: 0.2792\n",
      "Train loss: 0.18488\n",
      "Train loss: 0.23901\n",
      "Train loss: 0.4002\n",
      "Train loss: 0.082395\n",
      "Train loss: 0.41489\n",
      "Train loss: 0.40072\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.34727 - Accuracy: 0.877\n",
      "\n",
      "----- Epoch: 12 -----\n",
      "\n",
      "Train loss: 0.45162\n",
      "Train loss: 0.15087\n",
      "Train loss: 0.24638\n",
      "Train loss: 0.31179\n",
      "Train loss: 0.74361\n",
      "Train loss: 0.33302\n",
      "Train loss: 0.46301\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33908 - Accuracy: 0.874\n",
      "\n",
      "----- Epoch: 13 -----\n",
      "\n",
      "Train loss: 0.1627\n",
      "Train loss: 0.42594\n",
      "Train loss: 0.45738\n",
      "Train loss: 0.20708\n",
      "Train loss: 0.68612\n",
      "Train loss: 0.38477\n",
      "Train loss: 0.47661\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33097 - Accuracy: 0.878\n",
      "\n",
      "----- Epoch: 14 -----\n",
      "\n",
      "Train loss: 0.39816\n",
      "Train loss: 0.2911\n",
      "Train loss: 0.14559\n",
      "Train loss: 0.24984\n",
      "Train loss: 0.22532\n",
      "Train loss: 0.18221\n",
      "Train loss: 0.43713\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33173 - Accuracy: 0.878\n",
      "\n",
      "----- Epoch: 15 -----\n",
      "\n",
      "Train loss: 0.2891\n",
      "Train loss: 0.22879\n",
      "Train loss: 0.40927\n",
      "Train loss: 0.31544\n",
      "Train loss: 0.28742\n",
      "Train loss: 0.2766\n",
      "Train loss: 0.24043\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.3313 - Accuracy: 0.876\n",
      "\n",
      "----- Epoch: 16 -----\n",
      "\n",
      "Train loss: 0.26386\n",
      "Train loss: 0.25789\n",
      "Train loss: 0.16215\n",
      "Train loss: 0.2472\n",
      "Train loss: 0.32295\n",
      "Train loss: 0.082783\n",
      "Train loss: 0.4308\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32785 - Accuracy: 0.881\n",
      "\n",
      "----- Epoch: 17 -----\n",
      "\n",
      "Train loss: 0.26025\n",
      "Train loss: 0.29956\n",
      "Train loss: 0.3997\n",
      "Train loss: 0.20842\n",
      "Train loss: 0.43676\n",
      "Train loss: 0.18444\n",
      "Train loss: 0.10524\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32799 - Accuracy: 0.88\n",
      "\n",
      "----- Epoch: 18 -----\n",
      "\n",
      "Train loss: 0.22304\n",
      "Train loss: 0.27169\n",
      "Train loss: 0.23467\n",
      "Train loss: 0.25723\n",
      "Train loss: 0.17928\n",
      "Train loss: 0.098955\n",
      "Train loss: 0.1276\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32188 - Accuracy: 0.88\n",
      "\n",
      "----- Epoch: 19 -----\n",
      "\n",
      "Train loss: 0.22864\n",
      "Train loss: 0.30093\n",
      "Train loss: 0.38262\n",
      "Train loss: 0.1672\n",
      "Train loss: 0.16403\n",
      "Train loss: 0.098334\n",
      "Train loss: 0.28281\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31832 - Accuracy: 0.882\n",
      "\n",
      "----- Epoch: 20 -----\n",
      "\n",
      "Train loss: 0.30543\n",
      "Train loss: 0.1652\n",
      "Train loss: 0.041258\n",
      "Train loss: 0.14907\n",
      "Train loss: 0.219\n",
      "Train loss: 0.17628\n",
      "Train loss: 0.13203\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32649 - Accuracy: 0.881\n",
      "\n",
      "----- Epoch: 21 -----\n",
      "\n",
      "Train loss: 0.16708\n",
      "Train loss: 0.47525\n",
      "Train loss: 0.41136\n",
      "Train loss: 0.13398\n",
      "Train loss: 0.21565\n",
      "Train loss: 0.24865\n",
      "Train loss: 0.17426\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33949 - Accuracy: 0.875\n",
      "\n",
      "----- Epoch: 22 -----\n",
      "\n",
      "Train loss: 0.10476\n",
      "Train loss: 0.19401\n",
      "Train loss: 0.17725\n",
      "Train loss: 0.23121\n",
      "Train loss: 0.27434\n",
      "Train loss: 0.14029\n",
      "Train loss: 0.13689\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31168 - Accuracy: 0.883\n",
      "\n",
      "----- Epoch: 23 -----\n",
      "\n",
      "Train loss: 0.32519\n",
      "Train loss: 0.3036\n",
      "Train loss: 0.2987\n",
      "Train loss: 0.081709\n",
      "Train loss: 0.18478\n",
      "Train loss: 0.14603\n",
      "Train loss: 0.19315\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31219 - Accuracy: 0.882\n",
      "\n",
      "----- Epoch: 24 -----\n",
      "\n",
      "Train loss: 0.28752\n",
      "Train loss: 0.27447\n",
      "Train loss: 0.2017\n",
      "Train loss: 0.23241\n",
      "Train loss: 0.20218\n",
      "Train loss: 0.30046\n",
      "Train loss: 0.22079\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.34482 - Accuracy: 0.88\n",
      "\n",
      "----- Epoch: 25 -----\n",
      "\n",
      "Train loss: 0.37166\n",
      "Train loss: 0.13567\n",
      "Train loss: 0.25272\n",
      "Train loss: 0.1536\n",
      "Train loss: 0.35768\n",
      "Train loss: 0.20928\n",
      "Train loss: 0.22217\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31073 - Accuracy: 0.888\n",
      "\n",
      "----- Epoch: 26 -----\n",
      "\n",
      "Train loss: 0.15358\n",
      "Train loss: 0.41244\n",
      "Train loss: 0.32244\n",
      "Train loss: 0.064346\n",
      "Train loss: 0.14729\n",
      "Train loss: 0.22991\n",
      "Train loss: 0.092884\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31292 - Accuracy: 0.882\n",
      "\n",
      "----- Epoch: 27 -----\n",
      "\n",
      "Train loss: 0.22994\n",
      "Train loss: 0.2356\n",
      "Train loss: 0.31959\n",
      "Train loss: 0.16331\n",
      "Train loss: 0.3645\n",
      "Train loss: 0.22555\n",
      "Train loss: 0.19686\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31557 - Accuracy: 0.886\n",
      "\n",
      "----- Epoch: 28 -----\n",
      "\n",
      "Train loss: 0.30572\n",
      "Train loss: 0.13329\n",
      "Train loss: 0.19707\n",
      "Train loss: 0.16435\n",
      "Train loss: 0.10638\n",
      "Train loss: 0.49719\n",
      "Train loss: 0.11681\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.315 - Accuracy: 0.883\n",
      "\n",
      "----- Epoch: 29 -----\n",
      "\n",
      "Train loss: 0.21836\n",
      "Train loss: 0.1509\n",
      "Train loss: 0.31929\n",
      "Train loss: 0.30399\n",
      "Train loss: 0.22517\n",
      "Train loss: 0.21371\n",
      "Train loss: 0.16829\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.30298 - Accuracy: 0.889\n",
      "\n",
      "----- Epoch: 30 -----\n",
      "\n",
      "Train loss: 0.2175\n",
      "Train loss: 0.5188\n",
      "Train loss: 0.11899\n",
      "Train loss: 0.055857\n",
      "Train loss: 0.097997\n",
      "Train loss: 0.20755\n",
      "Train loss: 0.099952\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33048 - Accuracy: 0.883\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\n----- Epoch: {epoch+1} -----\\n')\n",
    "    train(train_loader, classif_model, loss_fn, classif_optim)\n",
    "    loss, acc = validate(valid_loader, classif_model, loss_fn)\n",
    "    test_loss.append(loss)\n",
    "    test_accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe0520",
   "metadata": {},
   "source": [
    "This is very similar to the performance shown in Geron's book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8bcfcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(30), test_accuracy, 'r-', label='Validation accuracy')\n",
    "plt.plot(np.arange(30), test_loss, 'b-', label='Validation loss')\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa42855",
   "metadata": {},
   "source": [
    "### Performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "246cc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_performance(dataloader, model):\n",
    "    test_accuracy = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            correct += (preds.argmax(1) == y).type(torch.float32).sum().item()\n",
    "    return correct / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c13e9632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8731"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_test_performance(test_loader, classif_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df76ea",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API\n",
    "\n",
    "For this example we use the California Housing dataset. After creating a training, validation, and test set, we must normalize the data and organize them into dataloaders.\n",
    "\n",
    "**Note**: in HOML3 the loss is the mean squared error (MSE), but the metric is the root mean squared error (RMSE), therefore to go from the loss to the metric, you have to take the square root of the loss. Our loss and the loss in HOML3 should be directly comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3999407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25dd2e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 8), (3870, 8), (5160, 8))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdde54a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.52140000e+00,  1.50000000e+01,  3.04994451e+00,  1.10654828e+00,\n",
       "        1.44700000e+03,  1.60599334e+00,  3.76300000e+01, -1.22430000e+02])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0adc10",
   "metadata": {},
   "source": [
    "The data is clearly not normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e51e94c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-124.35, 16305.0, -124.27, 35682.0, -124.25, 16122.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min(), x_train.max(), x_valid.min(), x_valid.max(), x_test.min(), x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04183e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, std_devs = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "means.shape, std_devs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b396fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = ((x_train - means) / std_devs).astype(np.float32)\n",
    "z_valid = ((x_valid - means) / std_devs).astype(np.float32)\n",
    "z_test = ((x_test - means) / std_devs).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "411e407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9218bb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4642746e-10, 1.0, 0.021390013, 3.6403675, -0.004968547, 0.99959093)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train.mean(), z_train.std(), z_valid.mean(), z_valid.std(), z_test.mean(), z_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a990127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor_train = torch.FloatTensor(z_train)\n",
    "y_tensor_train = torch.FloatTensor(y_train).unsqueeze(-1)\n",
    "x_tensor_valid = torch.FloatTensor(z_valid)\n",
    "y_tensor_valid = torch.FloatTensor(y_valid).unsqueeze(-1)\n",
    "x_tensor_test = torch.FloatTensor(z_test)\n",
    "y_tensor_test = torch.FloatTensor(y_test).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "563ecc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0214), tensor(3.6404))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor_valid.mean(), x_tensor_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a75419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = TensorDataset(x_tensor_train, y_tensor_train)\n",
    "valid_dset = TensorDataset(x_tensor_valid, y_tensor_valid)\n",
    "test_dset = TensorDataset(x_tensor_test, y_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e522ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3852c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential_model = nn.Sequential(\n",
    "            nn.Linear(in_features=8, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sequential_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78749533",
   "metadata": {},
   "source": [
    "### Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52aa1245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model = RegressionModel()\n",
    "regression_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7727e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = regression_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d8c444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(dataloader, model, loss_fn, optimizer):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x)\n",
    "        batch_loss = loss_fn(preds, y)\n",
    "        total_loss += batch_loss.item()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"Train Loss: {total_loss/num_batches:>.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96cbfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression(dataloader, model, loss_fn):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            total_loss += loss_fn(preds, y).item()\n",
    "        print(f'Validation Loss: {total_loss/num_batches:>.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd0006c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "regression_optim = optim.Adam(regression_model.parameters(), lr=1e-3, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3a1855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Epoch 1 -----\n",
      "Train Loss: 0.82841\n",
      "Validation Loss: 0.55169\n",
      "\n",
      " ----- Epoch 2 -----\n",
      "Train Loss: 0.37154\n",
      "Validation Loss: 2.2622\n",
      "\n",
      " ----- Epoch 3 -----\n",
      "Train Loss: 0.36366\n",
      "Validation Loss: 0.32544\n",
      "\n",
      " ----- Epoch 4 -----\n",
      "Train Loss: 0.33822\n",
      "Validation Loss: 0.64965\n",
      "\n",
      " ----- Epoch 5 -----\n",
      "Train Loss: 0.32801\n",
      "Validation Loss: 1.4544\n",
      "\n",
      " ----- Epoch 6 -----\n",
      "Train Loss: 0.32435\n",
      "Validation Loss: 1.4592\n",
      "\n",
      " ----- Epoch 7 -----\n",
      "Train Loss: 0.31361\n",
      "Validation Loss: 3.8273\n",
      "\n",
      " ----- Epoch 8 -----\n",
      "Train Loss: 0.34039\n",
      "Validation Loss: 0.36349\n",
      "\n",
      " ----- Epoch 9 -----\n",
      "Train Loss: 0.30402\n",
      "Validation Loss: 0.56003\n",
      "\n",
      " ----- Epoch 10 -----\n",
      "Train Loss: 0.30735\n",
      "Validation Loss: 1.3594\n",
      "\n",
      " ----- Epoch 11 -----\n",
      "Train Loss: 0.31131\n",
      "Validation Loss: 0.37016\n",
      "\n",
      " ----- Epoch 12 -----\n",
      "Train Loss: 0.29403\n",
      "Validation Loss: 1.0019\n",
      "\n",
      " ----- Epoch 13 -----\n",
      "Train Loss: 0.30035\n",
      "Validation Loss: 0.53096\n",
      "\n",
      " ----- Epoch 14 -----\n",
      "Train Loss: 0.29183\n",
      "Validation Loss: 0.40373\n",
      "\n",
      " ----- Epoch 15 -----\n",
      "Train Loss: 0.28541\n",
      "Validation Loss: 0.2945\n",
      "\n",
      " ----- Epoch 16 -----\n",
      "Train Loss: 0.28293\n",
      "Validation Loss: 0.31544\n",
      "\n",
      " ----- Epoch 17 -----\n",
      "Train Loss: 0.2811\n",
      "Validation Loss: 0.29509\n",
      "\n",
      " ----- Epoch 18 -----\n",
      "Train Loss: 0.27514\n",
      "Validation Loss: 0.34569\n",
      "\n",
      " ----- Epoch 19 -----\n",
      "Train Loss: 0.2757\n",
      "Validation Loss: 0.29587\n",
      "\n",
      " ----- Epoch 20 -----\n",
      "Train Loss: 0.27195\n",
      "Validation Loss: 0.53843\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f'\\n ----- Epoch {epoch+1} -----')\n",
    "    train_regression(train_loader, regression_model, loss_fn, regression_optim)\n",
    "    eval_regression(valid_loader, regression_model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c488a27",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d41f6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Linear(in_features=8, out_features=30)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layer2 = nn.Linear(in_features=30, out_features=30)\n",
    "        self.output_layer = nn.Linear(in_features=38, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.relu(self.hidden_layer1(x))\n",
    "        z = self.relu(self.hidden_layer2(z))\n",
    "        w = torch.cat((x, z), dim=-1)\n",
    "        return self.output_layer(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d3a2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "widedeep = WideAndDeep()\n",
    "widedeep.apply(init_weights)\n",
    "widedeep = widedeep.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90428cb",
   "metadata": {},
   "source": [
    "Note that we need to create another optimizer, as the existing one has been trained on a different architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cf1cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_optim = optim.Adam(widedeep.parameters(), lr=1e-3, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "445a9987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Epoch 1 -----\n",
      "Train Loss: 1.3558\n",
      "Validation Loss: 3.3985\n",
      "\n",
      " ----- Epoch 2 -----\n",
      "Train Loss: 0.46591\n",
      "Validation Loss: 0.57788\n",
      "\n",
      " ----- Epoch 3 -----\n",
      "Train Loss: 0.39137\n",
      "Validation Loss: 0.35826\n",
      "\n",
      " ----- Epoch 4 -----\n",
      "Train Loss: 0.37376\n",
      "Validation Loss: 0.34647\n",
      "\n",
      " ----- Epoch 5 -----\n",
      "Train Loss: 0.36318\n",
      "Validation Loss: 0.41629\n",
      "\n",
      " ----- Epoch 6 -----\n",
      "Train Loss: 0.35329\n",
      "Validation Loss: 1.2227\n",
      "\n",
      " ----- Epoch 7 -----\n",
      "Train Loss: 0.34655\n",
      "Validation Loss: 1.9933\n",
      "\n",
      " ----- Epoch 8 -----\n",
      "Train Loss: 0.36074\n",
      "Validation Loss: 1.7717\n",
      "\n",
      " ----- Epoch 9 -----\n",
      "Train Loss: 0.35534\n",
      "Validation Loss: 3.4004\n",
      "\n",
      " ----- Epoch 10 -----\n",
      "Train Loss: 0.3561\n",
      "Validation Loss: 1.7216\n",
      "\n",
      " ----- Epoch 11 -----\n",
      "Train Loss: 0.33839\n",
      "Validation Loss: 1.4947\n",
      "\n",
      " ----- Epoch 12 -----\n",
      "Train Loss: 0.32793\n",
      "Validation Loss: 0.4553\n",
      "\n",
      " ----- Epoch 13 -----\n",
      "Train Loss: 0.32642\n",
      "Validation Loss: 1.1004\n",
      "\n",
      " ----- Epoch 14 -----\n",
      "Train Loss: 0.32041\n",
      "Validation Loss: 0.85418\n",
      "\n",
      " ----- Epoch 15 -----\n",
      "Train Loss: 0.31686\n",
      "Validation Loss: 1.6981\n",
      "\n",
      " ----- Epoch 16 -----\n",
      "Train Loss: 0.32077\n",
      "Validation Loss: 1.0914\n",
      "\n",
      " ----- Epoch 17 -----\n",
      "Train Loss: 0.31024\n",
      "Validation Loss: 2.2085\n",
      "\n",
      " ----- Epoch 18 -----\n",
      "Train Loss: 0.32326\n",
      "Validation Loss: 1.3932\n",
      "\n",
      " ----- Epoch 19 -----\n",
      "Train Loss: 0.31602\n",
      "Validation Loss: 1.9561\n",
      "\n",
      " ----- Epoch 20 -----\n",
      "Train Loss: 0.31072\n",
      "Validation Loss: 1.6025\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f'\\n ----- Epoch {epoch+1} -----')\n",
    "    train_regression(train_loader, widedeep, loss_fn, wnd_optim)\n",
    "    eval_regression(valid_loader, widedeep, loss_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21afb750",
   "metadata": {},
   "source": [
    "### Sending inputs through two different paths\n",
    "\n",
    "The next example HOML3 sends features 0 to 4 to the wide path and features 2 to 7 through the deep path as shown below:\n",
    "\n",
    "![wide_deep](img/mls3_1015.png)\n",
    "\n",
    "To make this work we need to:\n",
    "\n",
    "1. Modify the Dataset so that it returns two inputs and one target.\n",
    "2. Modify the model so that it has two inputs.\n",
    "\n",
    "In this case, since there is only one output, the loss is unchanged. The source code for TensorDataset can be found [here](https://github.com/pytorch/pytorch/blob/03de15806e5d27ee4ef6d82dbcc66dac78f6e3bf/torch/utils/data/dataset.py#L193).\n",
    "\n",
    "We just need to redefine `__getitem__()` and we don't need to touch `__init__()`. Our modified implementation returns a tuple containing a tuple of inputs and the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c84dee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepDataset(TensorDataset):\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.tensors\n",
    "        return (x[index, :5], x[index, 2:], y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fc47e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_train_dset = WideAndDeepDataset(x_tensor_train, y_tensor_train)\n",
    "wnd_valid_dset = WideAndDeepDataset(x_tensor_valid, y_tensor_valid)\n",
    "wnd_test_dset = WideAndDeepDataset(x_tensor_test, y_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ca28b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_train_loader = DataLoader(wnd_train_dset, batch_size, shuffle=True)\n",
    "wnd_valid_loader = DataLoader(wnd_valid_dset, batch_size, shuffle=False)\n",
    "wnd_test_loader = DataLoader(wnd_test_dset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f638119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepTwoInputs(nn.Module):\n",
    "    # x_wide contains 5 features. x_deep contains 6\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Linear(in_features=6, out_features=30)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layer2 = nn.Linear(in_features=30, out_features=30)\n",
    "        self.output_layer = nn.Linear(in_features=35, out_features=1)\n",
    "    \n",
    "    def forward(self, x_wide, x_deep):\n",
    "        x_deep = self.relu(self.hidden_layer1(x_deep))\n",
    "        x_deep = self.relu(self.hidden_layer2(x_deep))\n",
    "        w = torch.cat((x_wide, x_deep), dim=-1)\n",
    "        return self.output_layer(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8fd86d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two_inputs = WideAndDeepTwoInputs()\n",
    "model_two_inputs.apply(init_weights)\n",
    "model_two_inputs = model_two_inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96b9b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_two_inputs(dataloader, model, loss_fn, optimizer):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    for batch, (x_wide, x_deep, y) in enumerate(dataloader):\n",
    "        x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
    "        preds = model(x_wide, x_deep)\n",
    "        batch_loss = loss_fn(preds, y)\n",
    "        total_loss += batch_loss.item()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"Train Loss: {total_loss/num_batches:>.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b27a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_two_inputs(dataloader, model, loss_fn):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_wide, x_deep, y in dataloader:\n",
    "            x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
    "            preds = model(x_wide, x_deep)\n",
    "            total_loss += loss_fn(preds, y).item()\n",
    "        print(f'Validation Loss: {total_loss/num_batches:>.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5be1ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_optim_two_inputs = optim.Adam(model_two_inputs.parameters(), lr=1e-3, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0974d573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 1 -----\n",
      "Train Loss: 1.3503\n",
      "Validation Loss: 1.2598\n",
      "\n",
      "----- Epoch: 2 -----\n",
      "Train Loss: 0.6067\n",
      "Validation Loss: 0.53724\n",
      "\n",
      "----- Epoch: 3 -----\n",
      "Train Loss: 0.48713\n",
      "Validation Loss: 0.44046\n",
      "\n",
      "----- Epoch: 4 -----\n",
      "Train Loss: 0.42955\n",
      "Validation Loss: 0.46473\n",
      "\n",
      "----- Epoch: 5 -----\n",
      "Train Loss: 0.39422\n",
      "Validation Loss: 0.65582\n",
      "\n",
      "----- Epoch: 6 -----\n",
      "Train Loss: 0.37524\n",
      "Validation Loss: 1.7768\n",
      "\n",
      "----- Epoch: 7 -----\n",
      "Train Loss: 0.37171\n",
      "Validation Loss: 1.0006\n",
      "\n",
      "----- Epoch: 8 -----\n",
      "Train Loss: 0.36554\n",
      "Validation Loss: 1.4627\n",
      "\n",
      "----- Epoch: 9 -----\n",
      "Train Loss: 0.35748\n",
      "Validation Loss: 1.1696\n",
      "\n",
      "----- Epoch: 10 -----\n",
      "Train Loss: 0.3555\n",
      "Validation Loss: 0.35428\n",
      "\n",
      "----- Epoch: 11 -----\n",
      "Train Loss: 0.3474\n",
      "Validation Loss: 0.49802\n",
      "\n",
      "----- Epoch: 12 -----\n",
      "Train Loss: 0.34205\n",
      "Validation Loss: 1.0847\n",
      "\n",
      "----- Epoch: 13 -----\n",
      "Train Loss: 0.34541\n",
      "Validation Loss: 1.3652\n",
      "\n",
      "----- Epoch: 14 -----\n",
      "Train Loss: 0.34595\n",
      "Validation Loss: 0.65656\n",
      "\n",
      "----- Epoch: 15 -----\n",
      "Train Loss: 0.33612\n",
      "Validation Loss: 0.3335\n",
      "\n",
      "----- Epoch: 16 -----\n",
      "Train Loss: 0.33086\n",
      "Validation Loss: 0.41547\n",
      "\n",
      "----- Epoch: 17 -----\n",
      "Train Loss: 0.33121\n",
      "Validation Loss: 0.32116\n",
      "\n",
      "----- Epoch: 18 -----\n",
      "Train Loss: 0.33461\n",
      "Validation Loss: 0.4008\n",
      "\n",
      "----- Epoch: 19 -----\n",
      "Train Loss: 0.3287\n",
      "Validation Loss: 0.56566\n",
      "\n",
      "----- Epoch: 20 -----\n",
      "Train Loss: 0.3285\n",
      "Validation Loss: 0.88187\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f\"\\n----- Epoch: {epoch+1} -----\")\n",
    "    train_two_inputs(wnd_train_loader, model_two_inputs, loss_fn, wnd_optim_two_inputs)\n",
    "    eval_two_inputs(wnd_valid_loader, model_two_inputs, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca2145e",
   "metadata": {},
   "source": [
    "### Multiple inputs and multiple outputs\n",
    "\n",
    "![multiple_outputs](img/multioutput.png)\n",
    "\n",
    "The model now returns two outputs which go into two separate losses that are then added together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90bb123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulitpleOutputsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Linear(in_features=6, out_features=30)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layer2 = nn.Linear(in_features=30, out_features=30)\n",
    "        self.output_layer = nn.Linear(in_features=35, out_features=1)\n",
    "        self.aux_output = nn.Linear(in_features=30, out_features=1)\n",
    "    \n",
    "    def forward(self, x_wide, x_deep):\n",
    "        x_deep = self.relu(self.hidden_layer1(x_deep))\n",
    "        x_deep = self.relu(self.hidden_layer2(x_deep))\n",
    "        main_out = self.output_layer(torch.cat((x_wide, x_deep), dim=-1))\n",
    "        aux_out = self.aux_output(x_deep)\n",
    "        return main_out, aux_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e9051a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_output_model = MulitpleOutputsModel()\n",
    "multi_output_model.apply(init_weights)\n",
    "multi_output_model = multi_output_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "476a545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_output_optim = optim.Adam(multi_output_model.parameters(), eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6fbbfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_two_outputs(dataloader, model, loss_fn, optimizer, weights):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    for batch, (x_wide, x_deep, y) in enumerate(dataloader):\n",
    "        x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
    "        main_preds, aux_preds = model(x_wide, x_deep)\n",
    "        main_loss, aux_loss = loss_fn(main_preds, y), loss_fn(aux_preds, y)\n",
    "        batch_loss = weights[0]*main_loss + weights[1]*aux_loss\n",
    "        total_loss += batch_loss.item()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"Train Loss: {total_loss/num_batches:>.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72ebc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_two_outputs(dataloader, model, loss_fn, weights):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_wide, x_deep, y in dataloader:\n",
    "            x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
    "            main_preds, aux_preds = model(x_wide, x_deep)\n",
    "            main_loss, aux_loss = loss_fn(main_preds, y), loss_fn(aux_preds, y)\n",
    "            batch_loss = weights[0]*main_loss + weights[1]*aux_loss\n",
    "            total_loss += batch_loss.item()\n",
    "        print(f'Validation Loss: {total_loss/num_batches:>.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4515f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 1 -----\n",
      "Train Loss: 1.8976\n",
      "Validation Loss: 5.2368\n",
      "\n",
      "----- Epoch: 2 -----\n",
      "Train Loss: 0.62028\n",
      "Validation Loss: 1.2181\n",
      "\n",
      "----- Epoch: 3 -----\n",
      "Train Loss: 0.46419\n",
      "Validation Loss: 0.68071\n",
      "\n",
      "----- Epoch: 4 -----\n",
      "Train Loss: 0.42583\n",
      "Validation Loss: 0.46964\n",
      "\n",
      "----- Epoch: 5 -----\n",
      "Train Loss: 0.40741\n",
      "Validation Loss: 0.4235\n",
      "\n",
      "----- Epoch: 6 -----\n",
      "Train Loss: 0.39361\n",
      "Validation Loss: 0.39545\n",
      "\n",
      "----- Epoch: 7 -----\n",
      "Train Loss: 0.38376\n",
      "Validation Loss: 0.38734\n",
      "\n",
      "----- Epoch: 8 -----\n",
      "Train Loss: 0.37563\n",
      "Validation Loss: 0.39303\n",
      "\n",
      "----- Epoch: 9 -----\n",
      "Train Loss: 0.36961\n",
      "Validation Loss: 0.36241\n",
      "\n",
      "----- Epoch: 10 -----\n",
      "Train Loss: 0.36345\n",
      "Validation Loss: 0.42451\n",
      "\n",
      "----- Epoch: 11 -----\n",
      "Train Loss: 0.35774\n",
      "Validation Loss: 0.37336\n",
      "\n",
      "----- Epoch: 12 -----\n",
      "Train Loss: 0.35484\n",
      "Validation Loss: 0.48186\n",
      "\n",
      "----- Epoch: 13 -----\n",
      "Train Loss: 0.35043\n",
      "Validation Loss: 0.48709\n",
      "\n",
      "----- Epoch: 14 -----\n",
      "Train Loss: 0.34607\n",
      "Validation Loss: 0.93839\n",
      "\n",
      "----- Epoch: 15 -----\n",
      "Train Loss: 0.34417\n",
      "Validation Loss: 0.85716\n",
      "\n",
      "----- Epoch: 16 -----\n",
      "Train Loss: 0.34235\n",
      "Validation Loss: 1.5644\n",
      "\n",
      "----- Epoch: 17 -----\n",
      "Train Loss: 0.34159\n",
      "Validation Loss: 2.0808\n",
      "\n",
      "----- Epoch: 18 -----\n",
      "Train Loss: 0.34689\n",
      "Validation Loss: 2.695\n",
      "\n",
      "----- Epoch: 19 -----\n",
      "Train Loss: 0.34805\n",
      "Validation Loss: 0.4928\n",
      "\n",
      "----- Epoch: 20 -----\n",
      "Train Loss: 0.33783\n",
      "Validation Loss: 0.69521\n"
     ]
    }
   ],
   "source": [
    "weights = (0.9, 0.1)\n",
    "for epoch in range(20):\n",
    "    print(f\"\\n----- Epoch: {epoch+1} -----\")\n",
    "    train_two_outputs(wnd_train_loader, multi_output_model, loss_fn, multi_output_optim, weights)\n",
    "    eval_two_outputs(wnd_valid_loader, multi_output_model, loss_fn, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42de02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
