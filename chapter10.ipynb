{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfe6779",
   "metadata": {},
   "source": [
    "# Chapter 10\n",
    "\n",
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8601b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76b9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data'\n",
    "full_train_dset = FashionMNIST(root=root_dir,\n",
    "                               train=True,\n",
    "                               download=True,\n",
    "                               transform=ToTensor())\n",
    "test_dset = FashionMNIST(root=root_dir,\n",
    "                         train=False,\n",
    "                         download=True,\n",
    "                         transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30ae606",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "if torch.cuda.device_count() == 2:\n",
    "    torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4c46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = Subset(full_train_dset, indices=range(55000))\n",
    "valid_dset = Subset(full_train_dset, indices=range(55000, 60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39bf7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dset), len(valid_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f761d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # Default batch size on keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef43a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5f4d3",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "In Geron's book the data are normalized by dividing by 255. The `ToTensor()` transform added to the Dataset definition takes care of this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c94788",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, tgt = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788b4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6fe9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02309bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential_model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=784, out_features=300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=300, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features=10))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sequential_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c057db0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model = MyModel()\n",
    "classif_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5596b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0097, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22176dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0194,  0.0207,  0.0205, -0.0123, -0.0234,  0.0215,  0.0184, -0.0249,\n",
       "         0.0315, -0.0067], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].weight[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce2bc7",
   "metadata": {},
   "source": [
    "## Weight initialization\n",
    "\n",
    "In Keras weights in a dense layer are, [by default](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense), initialized with a Glorot Uniform initialization.\n",
    "\n",
    "In Pytorch weights in a linear layer are, [by default](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) initialized with a uniform distribution with  U(âˆ’k,k) where k=1/in_features. This is essentially a LeCun uniform initialization. Note that in PyTorch, Glorot initialization is called Xavier initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9437ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf40d666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19df074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cecb27f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0380, -0.0405,  0.0061, -0.0318,  0.0638, -0.0513,  0.0744, -0.0589,\n",
       "         0.0524,  0.0436], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.sequential_model[1].weight[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f506245",
   "metadata": {},
   "source": [
    "Both the bias and the weight look different. We assume that we are using the same initialization approach as Keras.\n",
    "\n",
    "The Keras model has a final softmax activation. If we use PyTorch cross-entropy loss, the softmax is fused in the loss, so we don't need to include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74120b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d87bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b844b7f",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "The example in Geron's book uses the \"sgd\" optimizer, which I suspect corresponds to the [default settings](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/SGD), i.e., lr = 0.01 and momentum = 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7487429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_optim = optim.SGD(classif_model.parameters(), lr=0.01, momentum=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e26dc5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x)\n",
    "        batch_loss = loss_fn(preds, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 250 == 0:\n",
    "            print(f'Train loss: {batch_loss.item():>.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67df4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            total_loss += loss_fn(preds, y).item()\n",
    "            correct += (preds.argmax(1) == y).type(torch.float).sum().item()\n",
    "    avg_batch_loss = total_loss / num_batches\n",
    "    accuracy = correct / num_obs\n",
    "    print('Validation:')\n",
    "    print(f'\\nAverage loss: {avg_batch_loss:>.5} - Accuracy: {accuracy:>.3}')\n",
    "    return avg_batch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffd85440",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aef7cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 1 -----\n",
      "\n",
      "Train loss: 2.2598\n",
      "Train loss: 0.8287\n",
      "Train loss: 0.87436\n",
      "Train loss: 0.64119\n",
      "Train loss: 0.65544\n",
      "Train loss: 0.55431\n",
      "Train loss: 0.72651\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.53774 - Accuracy: 0.812\n",
      "\n",
      "----- Epoch: 2 -----\n",
      "\n",
      "Train loss: 0.45458\n",
      "Train loss: 0.3924\n",
      "Train loss: 0.43722\n",
      "Train loss: 0.41766\n",
      "Train loss: 0.57856\n",
      "Train loss: 0.40585\n",
      "Train loss: 0.4903\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.4529 - Accuracy: 0.838\n",
      "\n",
      "----- Epoch: 3 -----\n",
      "\n",
      "Train loss: 0.50073\n",
      "Train loss: 0.37522\n",
      "Train loss: 0.33948\n",
      "Train loss: 0.53763\n",
      "Train loss: 0.62118\n",
      "Train loss: 0.77319\n",
      "Train loss: 0.50318\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.43388 - Accuracy: 0.84\n",
      "\n",
      "----- Epoch: 4 -----\n",
      "\n",
      "Train loss: 0.28299\n",
      "Train loss: 0.83093\n",
      "Train loss: 0.27268\n",
      "Train loss: 0.39683\n",
      "Train loss: 0.27692\n",
      "Train loss: 0.48836\n",
      "Train loss: 0.47582\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.40688 - Accuracy: 0.856\n",
      "\n",
      "----- Epoch: 5 -----\n",
      "\n",
      "Train loss: 0.14218\n",
      "Train loss: 0.43433\n",
      "Train loss: 0.50023\n",
      "Train loss: 0.41341\n",
      "Train loss: 0.57753\n",
      "Train loss: 0.16595\n",
      "Train loss: 0.15647\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.38915 - Accuracy: 0.86\n",
      "\n",
      "----- Epoch: 6 -----\n",
      "\n",
      "Train loss: 0.23373\n",
      "Train loss: 0.45709\n",
      "Train loss: 0.15961\n",
      "Train loss: 0.17206\n",
      "Train loss: 0.34764\n",
      "Train loss: 0.37806\n",
      "Train loss: 0.6502\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.40823 - Accuracy: 0.856\n",
      "\n",
      "----- Epoch: 7 -----\n",
      "\n",
      "Train loss: 0.42731\n",
      "Train loss: 0.62331\n",
      "Train loss: 0.33892\n",
      "Train loss: 0.61542\n",
      "Train loss: 0.24616\n",
      "Train loss: 0.17202\n",
      "Train loss: 0.52806\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.42722 - Accuracy: 0.845\n",
      "\n",
      "----- Epoch: 8 -----\n",
      "\n",
      "Train loss: 0.27198\n",
      "Train loss: 0.30982\n",
      "Train loss: 0.31009\n",
      "Train loss: 0.1938\n",
      "Train loss: 0.4052\n",
      "Train loss: 0.3241\n",
      "Train loss: 0.23758\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.38656 - Accuracy: 0.857\n",
      "\n",
      "----- Epoch: 9 -----\n",
      "\n",
      "Train loss: 0.28184\n",
      "Train loss: 0.30461\n",
      "Train loss: 0.35539\n",
      "Train loss: 0.44377\n",
      "Train loss: 0.21725\n",
      "Train loss: 0.34628\n",
      "Train loss: 0.28585\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.35342 - Accuracy: 0.876\n",
      "\n",
      "----- Epoch: 10 -----\n",
      "\n",
      "Train loss: 0.24397\n",
      "Train loss: 0.21663\n",
      "Train loss: 0.27163\n",
      "Train loss: 0.36721\n",
      "Train loss: 0.55658\n",
      "Train loss: 0.25759\n",
      "Train loss: 0.13926\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.36321 - Accuracy: 0.87\n",
      "\n",
      "----- Epoch: 11 -----\n",
      "\n",
      "Train loss: 0.35741\n",
      "Train loss: 0.37808\n",
      "Train loss: 0.15047\n",
      "Train loss: 0.23569\n",
      "Train loss: 0.099428\n",
      "Train loss: 0.11818\n",
      "Train loss: 0.22942\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.35244 - Accuracy: 0.873\n",
      "\n",
      "----- Epoch: 12 -----\n",
      "\n",
      "Train loss: 0.47253\n",
      "Train loss: 0.24634\n",
      "Train loss: 0.38109\n",
      "Train loss: 0.38882\n",
      "Train loss: 0.3654\n",
      "Train loss: 0.39176\n",
      "Train loss: 0.54841\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.35881 - Accuracy: 0.875\n",
      "\n",
      "----- Epoch: 13 -----\n",
      "\n",
      "Train loss: 0.31275\n",
      "Train loss: 0.30477\n",
      "Train loss: 0.3138\n",
      "Train loss: 0.73404\n",
      "Train loss: 0.43621\n",
      "Train loss: 0.59978\n",
      "Train loss: 0.33391\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33777 - Accuracy: 0.874\n",
      "\n",
      "----- Epoch: 14 -----\n",
      "\n",
      "Train loss: 0.33943\n",
      "Train loss: 0.36681\n",
      "Train loss: 0.20188\n",
      "Train loss: 0.21196\n",
      "Train loss: 0.2069\n",
      "Train loss: 0.26628\n",
      "Train loss: 0.20335\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.3538 - Accuracy: 0.872\n",
      "\n",
      "----- Epoch: 15 -----\n",
      "\n",
      "Train loss: 0.38541\n",
      "Train loss: 0.2034\n",
      "Train loss: 0.26049\n",
      "Train loss: 0.26698\n",
      "Train loss: 0.18754\n",
      "Train loss: 0.26247\n",
      "Train loss: 0.25614\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33281 - Accuracy: 0.878\n",
      "\n",
      "----- Epoch: 16 -----\n",
      "\n",
      "Train loss: 0.29543\n",
      "Train loss: 0.32122\n",
      "Train loss: 0.19084\n",
      "Train loss: 0.25199\n",
      "Train loss: 0.29417\n",
      "Train loss: 0.18123\n",
      "Train loss: 0.33448\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.328 - Accuracy: 0.879\n",
      "\n",
      "----- Epoch: 17 -----\n",
      "\n",
      "Train loss: 0.10004\n",
      "Train loss: 0.4115\n",
      "Train loss: 0.079155\n",
      "Train loss: 0.25129\n",
      "Train loss: 0.13817\n",
      "Train loss: 0.21711\n",
      "Train loss: 0.50314\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32994 - Accuracy: 0.879\n",
      "\n",
      "----- Epoch: 18 -----\n",
      "\n",
      "Train loss: 0.17555\n",
      "Train loss: 0.10971\n",
      "Train loss: 0.22332\n",
      "Train loss: 0.43432\n",
      "Train loss: 0.084924\n",
      "Train loss: 0.30581\n",
      "Train loss: 0.20674\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.34557 - Accuracy: 0.877\n",
      "\n",
      "----- Epoch: 19 -----\n",
      "\n",
      "Train loss: 0.34031\n",
      "Train loss: 0.27101\n",
      "Train loss: 0.25315\n",
      "Train loss: 0.43936\n",
      "Train loss: 0.21063\n",
      "Train loss: 0.2741\n",
      "Train loss: 0.34507\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31872 - Accuracy: 0.885\n",
      "\n",
      "----- Epoch: 20 -----\n",
      "\n",
      "Train loss: 0.51181\n",
      "Train loss: 0.23054\n",
      "Train loss: 0.28455\n",
      "Train loss: 0.29724\n",
      "Train loss: 0.23525\n",
      "Train loss: 0.31451\n",
      "Train loss: 0.14325\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32532 - Accuracy: 0.877\n",
      "\n",
      "----- Epoch: 21 -----\n",
      "\n",
      "Train loss: 0.099218\n",
      "Train loss: 0.21083\n",
      "Train loss: 0.13376\n",
      "Train loss: 0.19178\n",
      "Train loss: 0.27106\n",
      "Train loss: 0.21822\n",
      "Train loss: 0.31065\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.33565 - Accuracy: 0.879\n",
      "\n",
      "----- Epoch: 22 -----\n",
      "\n",
      "Train loss: 0.23203\n",
      "Train loss: 0.29132\n",
      "Train loss: 0.2622\n",
      "Train loss: 0.19461\n",
      "Train loss: 0.27438\n",
      "Train loss: 0.14457\n",
      "Train loss: 0.35121\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32049 - Accuracy: 0.884\n",
      "\n",
      "----- Epoch: 23 -----\n",
      "\n",
      "Train loss: 0.55905\n",
      "Train loss: 0.21219\n",
      "Train loss: 0.37032\n",
      "Train loss: 0.19948\n",
      "Train loss: 0.30535\n",
      "Train loss: 0.096898\n",
      "Train loss: 0.28119\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31216 - Accuracy: 0.884\n",
      "\n",
      "----- Epoch: 24 -----\n",
      "\n",
      "Train loss: 0.40228\n",
      "Train loss: 0.17665\n",
      "Train loss: 0.32734\n",
      "Train loss: 0.20205\n",
      "Train loss: 0.11647\n",
      "Train loss: 0.31442\n",
      "Train loss: 0.24101\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32593 - Accuracy: 0.884\n",
      "\n",
      "----- Epoch: 25 -----\n",
      "\n",
      "Train loss: 0.12635\n",
      "Train loss: 0.16596\n",
      "Train loss: 0.15837\n",
      "Train loss: 0.42724\n",
      "Train loss: 0.31222\n",
      "Train loss: 0.29761\n",
      "Train loss: 0.26486\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.34239 - Accuracy: 0.873\n",
      "\n",
      "----- Epoch: 26 -----\n",
      "\n",
      "Train loss: 0.24702\n",
      "Train loss: 0.29329\n",
      "Train loss: 0.13833\n",
      "Train loss: 0.088246\n",
      "Train loss: 0.25923\n",
      "Train loss: 0.11352\n",
      "Train loss: 0.2843\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31315 - Accuracy: 0.885\n",
      "\n",
      "----- Epoch: 27 -----\n",
      "\n",
      "Train loss: 0.094673\n",
      "Train loss: 0.12274\n",
      "Train loss: 0.18742\n",
      "Train loss: 0.5705\n",
      "Train loss: 0.11529\n",
      "Train loss: 0.059636\n",
      "Train loss: 0.21775\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.31048 - Accuracy: 0.887\n",
      "\n",
      "----- Epoch: 28 -----\n",
      "\n",
      "Train loss: 0.216\n",
      "Train loss: 0.14843\n",
      "Train loss: 0.085651\n",
      "Train loss: 0.23154\n",
      "Train loss: 0.19548\n",
      "Train loss: 0.32036\n",
      "Train loss: 0.31082\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.3161 - Accuracy: 0.888\n",
      "\n",
      "----- Epoch: 29 -----\n",
      "\n",
      "Train loss: 0.39598\n",
      "Train loss: 0.087764\n",
      "Train loss: 0.51649\n",
      "Train loss: 0.22298\n",
      "Train loss: 0.13725\n",
      "Train loss: 0.25192\n",
      "Train loss: 0.2429\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32668 - Accuracy: 0.885\n",
      "\n",
      "----- Epoch: 30 -----\n",
      "\n",
      "Train loss: 0.07163\n",
      "Train loss: 0.17833\n",
      "Train loss: 0.40595\n",
      "Train loss: 0.042037\n",
      "Train loss: 0.26562\n",
      "Train loss: 0.2365\n",
      "Train loss: 0.10373\n",
      "Validation:\n",
      "\n",
      "Average loss: 0.32382 - Accuracy: 0.887\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\n----- Epoch: {epoch+1} -----\\n')\n",
    "    train(train_loader, classif_model, loss_fn, classif_optim)\n",
    "    loss, acc = validate(valid_loader, classif_model, loss_fn)\n",
    "    test_loss.append(loss)\n",
    "    test_accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe0520",
   "metadata": {},
   "source": [
    "This is very similar to the performance shown in Geron's book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8bcfcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(30), test_accuracy, 'r-', label='Validation accuracy')\n",
    "plt.plot(np.arange(30), test_loss, 'b-', label='Validation loss')\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa42855",
   "metadata": {},
   "source": [
    "### Performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "246cc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_performance(dataloader, model):\n",
    "    test_accuracy = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            correct += (preds.argmax(1) == y).type(torch.float32).sum().item()\n",
    "    return correct / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c13e9632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8782"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_test_performance(test_loader, classif_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df76ea",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API\n",
    "\n",
    "For this example we use the California Housing dataset. After creating a training, validation, and test set, we must normalize the data and organize them into dataloaders.\n",
    "\n",
    "**Note**: in HOML3 the loss is the mean squared error (MSE), but the metric is the root mean squared error (RMSE), therefore to go from the loss to the metric, you have to take the square root of the loss. Our loss and the loss in HOML3 should be directly comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3999407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25dd2e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 8), (3870, 8), (5160, 8))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdde54a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.52140000e+00,  1.50000000e+01,  3.04994451e+00,  1.10654828e+00,\n",
       "        1.44700000e+03,  1.60599334e+00,  3.76300000e+01, -1.22430000e+02])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1af89a",
   "metadata": {},
   "source": [
    "The data is clearly not normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e10c4d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-124.35, 16305.0, -124.27, 35682.0, -124.25, 16122.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min(), x_train.max(), x_valid.min(), x_valid.max(), x_test.min(), x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04183e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, std_devs = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "means.shape, std_devs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b396fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = ((x_train - means) / std_devs).astype(np.float32)\n",
    "z_valid = ((x_valid - means) / std_devs).astype(np.float32)\n",
    "z_test = ((x_test - means) / std_devs).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "411e407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77db7ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4642746e-10, 1.0, 0.021390013, 3.6403675, -0.004968547, 0.99959093)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train.mean(), z_train.std(), z_valid.mean(), z_valid.std(), z_test.mean(), z_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46ec0bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor_train = torch.FloatTensor(z_train)\n",
    "y_tensor_train = torch.FloatTensor(y_train).unsqueeze(-1)\n",
    "x_tensor_valid = torch.FloatTensor(z_valid)\n",
    "y_tensor_valid = torch.FloatTensor(y_valid).unsqueeze(-1)\n",
    "x_tensor_test = torch.FloatTensor(z_test)\n",
    "y_tensor_test = torch.FloatTensor(y_test).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c26a3889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0214), tensor(3.6404))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor_valid.mean(), x_tensor_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a75419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = TensorDataset(x_tensor_train, y_tensor_train)\n",
    "valid_dset = TensorDataset(x_tensor_valid, y_tensor_valid)\n",
    "test_dset = TensorDataset(x_tensor_test, y_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e522ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3852c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential_model = nn.Sequential(\n",
    "            nn.Linear(in_features=8, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sequential_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78749533",
   "metadata": {},
   "source": [
    "### Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52aa1245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionModel(\n",
       "  (sequential_model): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model = RegressionModel()\n",
    "regression_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7727e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = regression_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d8c444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(dataloader, model, loss_fn, optimizer):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x)\n",
    "        batch_loss = loss_fn(preds, y)\n",
    "        total_loss += batch_loss.item()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"Train Loss: {total_loss/num_batches:>.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96cbfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression(dataloader, model, loss_fn):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            total_loss += loss_fn(preds, y).item()\n",
    "        print(f'Validation Loss: {total_loss/num_batches:>.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd0006c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "regression_optim = optim.Adam(regression_model.parameters(), lr=1e-3, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3a1855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Epoch 1 -----\n",
      "Train Loss: 0.81788\n",
      "Validation Loss: 0.37046\n",
      "\n",
      " ----- Epoch 2 -----\n",
      "Train Loss: 0.37564\n",
      "Validation Loss: 0.38949\n",
      "\n",
      " ----- Epoch 3 -----\n",
      "Train Loss: 0.34257\n",
      "Validation Loss: 0.59244\n",
      "\n",
      " ----- Epoch 4 -----\n",
      "Train Loss: 0.33984\n",
      "Validation Loss: 1.1651\n",
      "\n",
      " ----- Epoch 5 -----\n",
      "Train Loss: 0.32233\n",
      "Validation Loss: 3.556\n",
      "\n",
      " ----- Epoch 6 -----\n",
      "Train Loss: 0.33994\n",
      "Validation Loss: 0.30953\n",
      "\n",
      " ----- Epoch 7 -----\n",
      "Train Loss: 0.30563\n",
      "Validation Loss: 1.527\n",
      "\n",
      " ----- Epoch 8 -----\n",
      "Train Loss: 0.30651\n",
      "Validation Loss: 1.0936\n",
      "\n",
      " ----- Epoch 9 -----\n",
      "Train Loss: 0.29389\n",
      "Validation Loss: 3.9415\n",
      "\n",
      " ----- Epoch 10 -----\n",
      "Train Loss: 0.29799\n",
      "Validation Loss: 1.1277\n",
      "\n",
      " ----- Epoch 11 -----\n",
      "Train Loss: 0.31273\n",
      "Validation Loss: 1.1509\n",
      "\n",
      " ----- Epoch 12 -----\n",
      "Train Loss: 0.28833\n",
      "Validation Loss: 0.27233\n",
      "\n",
      " ----- Epoch 13 -----\n",
      "Train Loss: 0.28\n",
      "Validation Loss: 0.28907\n",
      "\n",
      " ----- Epoch 14 -----\n",
      "Train Loss: 0.27736\n",
      "Validation Loss: 0.37452\n",
      "\n",
      " ----- Epoch 15 -----\n",
      "Train Loss: 0.2728\n",
      "Validation Loss: 0.27716\n",
      "\n",
      " ----- Epoch 16 -----\n",
      "Train Loss: 0.27477\n",
      "Validation Loss: 0.44149\n",
      "\n",
      " ----- Epoch 17 -----\n",
      "Train Loss: 0.27224\n",
      "Validation Loss: 0.30305\n",
      "\n",
      " ----- Epoch 18 -----\n",
      "Train Loss: 0.27174\n",
      "Validation Loss: 0.75143\n",
      "\n",
      " ----- Epoch 19 -----\n",
      "Train Loss: 0.26809\n",
      "Validation Loss: 0.3043\n",
      "\n",
      " ----- Epoch 20 -----\n",
      "Train Loss: 0.26364\n",
      "Validation Loss: 0.60484\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f'\\n ----- Epoch {epoch+1} -----')\n",
    "    train_regression(train_loader, regression_model, loss_fn, regression_optim)\n",
    "    eval_regression(valid_loader, regression_model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c488a27",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d41f6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Linear(in_features=8, out_features=30)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layer2 = nn.Linear(in_features=30, out_features=30)\n",
    "        self.output_layer = nn.Linear(in_features=38, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.relu(self.hidden_layer1(x))\n",
    "        z = self.relu(self.hidden_layer2(z))\n",
    "        w = torch.cat((x, z), dim=-1)\n",
    "        return self.output_layer(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d3a2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "widedeep = WideAndDeep()\n",
    "widedeep.apply(init_weights)\n",
    "widedeep = widedeep.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90428cb",
   "metadata": {},
   "source": [
    "Note that we need to create another optimizer, as the existing one has been trained on a different architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cf1cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_optim = optim.Adam(widedeep.parameters(), lr=1e-3, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "445a9987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Epoch 1 -----\n",
      "Train Loss: 1.1853\n",
      "Validation Loss: 0.67669\n",
      "\n",
      " ----- Epoch 2 -----\n",
      "Train Loss: 0.44997\n",
      "Validation Loss: 0.38968\n",
      "\n",
      " ----- Epoch 3 -----\n",
      "Train Loss: 0.39356\n",
      "Validation Loss: 0.35445\n",
      "\n",
      " ----- Epoch 4 -----\n",
      "Train Loss: 0.36832\n",
      "Validation Loss: 0.4875\n",
      "\n",
      " ----- Epoch 5 -----\n",
      "Train Loss: 0.35712\n",
      "Validation Loss: 0.35604\n",
      "\n",
      " ----- Epoch 6 -----\n",
      "Train Loss: 0.34796\n",
      "Validation Loss: 0.33302\n",
      "\n",
      " ----- Epoch 7 -----\n",
      "Train Loss: 0.33967\n",
      "Validation Loss: 0.42444\n",
      "\n",
      " ----- Epoch 8 -----\n",
      "Train Loss: 0.33522\n",
      "Validation Loss: 1.9243\n",
      "\n",
      " ----- Epoch 9 -----\n",
      "Train Loss: 0.33862\n",
      "Validation Loss: 3.0885\n",
      "\n",
      " ----- Epoch 10 -----\n",
      "Train Loss: 0.3588\n",
      "Validation Loss: 1.915\n",
      "\n",
      " ----- Epoch 11 -----\n",
      "Train Loss: 0.3326\n",
      "Validation Loss: 3.8271\n",
      "\n",
      " ----- Epoch 12 -----\n",
      "Train Loss: 0.35038\n",
      "Validation Loss: 1.4098\n",
      "\n",
      " ----- Epoch 13 -----\n",
      "Train Loss: 0.32446\n",
      "Validation Loss: 1.9612\n",
      "\n",
      " ----- Epoch 14 -----\n",
      "Train Loss: 0.32261\n",
      "Validation Loss: 1.2074\n",
      "\n",
      " ----- Epoch 15 -----\n",
      "Train Loss: 0.32098\n",
      "Validation Loss: 1.7509\n",
      "\n",
      " ----- Epoch 16 -----\n",
      "Train Loss: 0.32051\n",
      "Validation Loss: 1.0638\n",
      "\n",
      " ----- Epoch 17 -----\n",
      "Train Loss: 0.31646\n",
      "Validation Loss: 2.1845\n",
      "\n",
      " ----- Epoch 18 -----\n",
      "Train Loss: 0.3187\n",
      "Validation Loss: 1.4048\n",
      "\n",
      " ----- Epoch 19 -----\n",
      "Train Loss: 0.31782\n",
      "Validation Loss: 1.6842\n",
      "\n",
      " ----- Epoch 20 -----\n",
      "Train Loss: 0.31187\n",
      "Validation Loss: 0.6615\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f'\\n ----- Epoch {epoch+1} -----')\n",
    "    train_regression(train_loader, widedeep, loss_fn, wnd_optim)\n",
    "    eval_regression(valid_loader, widedeep, loss_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04cfb561",
   "metadata": {},
   "source": [
    "### Sending inputs through two different paths\n",
    "\n",
    "The next example HOML3 sends features 0 to 4 to the wide path and features 2 to 7 through the deep path as shown below:\n",
    "\n",
    "![wide_deep](img/mls3_1015.png)\n",
    "\n",
    "To make this work we need to:\n",
    "\n",
    "1. Modify the Dataset so that it returns two inputs and one target.\n",
    "2. Modify the model so that it has two inputs.\n",
    "\n",
    "In this case, since there is only one output, the loss is unchanged. The source code for TensorDataset can be found [here](https://github.com/pytorch/pytorch/blob/03de15806e5d27ee4ef6d82dbcc66dac78f6e3bf/torch/utils/data/dataset.py#L193).\n",
    "\n",
    "We just need to redefine `__getitem__()` and we don't need to touch `__init__()`. Our modified implementation returns a tuple containing a tuple of inputs and the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22ac3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepDataset(TensorDataset):\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.tensors\n",
    "        return (x[index, :5], x[index, 2:], y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8c32b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_train_dset = WideAndDeepDataset(x_tensor_train, y_tensor_train)\n",
    "wnd_valid_dset = WideAndDeepDataset(x_tensor_valid, y_tensor_valid)\n",
    "wnd_test_dset = WideAndDeepDataset(x_tensor_test, y_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90771006",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_train_loader = DataLoader(wnd_train_dset, batch_size, shuffle=True)\n",
    "wnd_valid_loader = DataLoader(wnd_valid_dset, batch_size, shuffle=False)\n",
    "wnd_test_loader = DataLoader(wnd_test_dset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b71c8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepTwoInputs(nn.Module):\n",
    "    # x_wide contains 5 features. x_deep contains 6\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Linear(in_features=6, out_features=30)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layer2 = nn.Linear(in_features=30, out_features=30)\n",
    "        self.output_layer = nn.Linear(in_features=35, out_features=1)\n",
    "    \n",
    "    def forward(self, x_wide, x_deep):\n",
    "        x_deep = self.relu(self.hidden_layer1(x_deep))\n",
    "        x_deep = self.relu(self.hidden_layer2(x_deep))\n",
    "        w = torch.cat((x_wide, x_deep), dim=-1)\n",
    "        return self.output_layer(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6cf11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two_inputs = WideAndDeepTwoInputs()\n",
    "model_two_inputs.apply(init_weights)\n",
    "model_two_inputs = model_two_inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7418c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_two_inputs(dataloader, model, loss_fn, optimizer):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    for batch, (x_wide, x_deep, y) in enumerate(dataloader):\n",
    "        x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
    "        preds = model(x_wide, x_deep)\n",
    "        batch_loss = loss_fn(preds, y)\n",
    "        total_loss += batch_loss.item()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"Train Loss: {total_loss/num_batches:>.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed5fe9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_two_inputs(dataloader, model, loss_fn):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_wide, x_deep, y in dataloader:\n",
    "            x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
    "            preds = model(x_wide, x_deep)\n",
    "            total_loss += loss_fn(preds, y).item()\n",
    "        print(f'Validation Loss: {total_loss/num_batches:>.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84f52118",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_optim_two_inputs = optim.Adam(model_two_inputs.parameters(), lr=1e-3, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d67f5a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 1 -----\n",
      "Train Loss: 1.7308\n",
      "Validation Loss: 0.82043\n",
      "\n",
      "----- Epoch: 2 -----\n",
      "Train Loss: 0.53574\n",
      "Validation Loss: 0.76607\n",
      "\n",
      "----- Epoch: 3 -----\n",
      "Train Loss: 0.44516\n",
      "Validation Loss: 0.45189\n",
      "\n",
      "----- Epoch: 4 -----\n",
      "Train Loss: 0.42589\n",
      "Validation Loss: 0.40792\n",
      "\n",
      "----- Epoch: 5 -----\n",
      "Train Loss: 0.39487\n",
      "Validation Loss: 0.6785\n",
      "\n",
      "----- Epoch: 6 -----\n",
      "Train Loss: 0.38849\n",
      "Validation Loss: 0.64042\n",
      "\n",
      "----- Epoch: 7 -----\n",
      "Train Loss: 0.37544\n",
      "Validation Loss: 5.0535\n",
      "\n",
      "----- Epoch: 8 -----\n",
      "Train Loss: 0.39214\n",
      "Validation Loss: 2.7496\n",
      "\n",
      "----- Epoch: 9 -----\n",
      "Train Loss: 0.38007\n",
      "Validation Loss: 2.6884\n",
      "\n",
      "----- Epoch: 10 -----\n",
      "Train Loss: 0.37568\n",
      "Validation Loss: 3.959\n",
      "\n",
      "----- Epoch: 11 -----\n",
      "Train Loss: 0.39184\n",
      "Validation Loss: 1.7122\n",
      "\n",
      "----- Epoch: 12 -----\n",
      "Train Loss: 0.36096\n",
      "Validation Loss: 1.4377\n",
      "\n",
      "----- Epoch: 13 -----\n",
      "Train Loss: 0.35708\n",
      "Validation Loss: 1.1323\n",
      "\n",
      "----- Epoch: 14 -----\n",
      "Train Loss: 0.35312\n",
      "Validation Loss: 0.78477\n",
      "\n",
      "----- Epoch: 15 -----\n",
      "Train Loss: 0.34501\n",
      "Validation Loss: 0.95389\n",
      "\n",
      "----- Epoch: 16 -----\n",
      "Train Loss: 0.34736\n",
      "Validation Loss: 0.67227\n",
      "\n",
      "----- Epoch: 17 -----\n",
      "Train Loss: 0.34284\n",
      "Validation Loss: 0.6848\n",
      "\n",
      "----- Epoch: 18 -----\n",
      "Train Loss: 0.34312\n",
      "Validation Loss: 1.3253\n",
      "\n",
      "----- Epoch: 19 -----\n",
      "Train Loss: 0.33997\n",
      "Validation Loss: 1.9801\n",
      "\n",
      "----- Epoch: 20 -----\n",
      "Train Loss: 0.3476\n",
      "Validation Loss: 2.2867\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f\"\\n----- Epoch: {epoch+1} -----\")\n",
    "    train_two_inputs(wnd_train_loader, model_two_inputs, loss_fn, wnd_optim_two_inputs)\n",
    "    eval_two_inputs(wnd_valid_loader, model_two_inputs, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531c2d6",
   "metadata": {},
   "source": [
    "### Multiple inputs and multiple outputs\n",
    "\n",
    "![multiple_outputs](img/multioutput.png)\n",
    "\n",
    "The model now returns two outputs which go into two separate losses that are then added together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdb4aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulitpleOutputsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Linear(in_features=6, out_features=30)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layer2 = nn.Linear(in_features=30, out_features=30)\n",
    "        self.output_layer = nn.Linear(in_features=35, out_features=1)\n",
    "        self.aux_output = nn.Linear(in_features=30, out_features=1)\n",
    "    \n",
    "    def forward(self, x_wide, x_deep):\n",
    "        x_deep = self.relu(self.hidden_layer1(x_deep))\n",
    "        x_deep = self.relu(self.hidden_layer2(x_deep))\n",
    "        main_out = self.output_layer(torch.cat((x_wide, x_deep), dim=-1))\n",
    "        aux_out = self.aux_output(x_deep)\n",
    "        return main_out, aux_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e2d5a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_output_model = MulitpleOutputsModel()\n",
    "multi_output_model.apply(init_weights)\n",
    "multi_output_model = multi_output_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80021159",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_output_optim = optim.Adam(multi_output_model.parameters(), eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b339fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_two_outputs(dataloader, model, loss_fn, optimizer, weights):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    for batch, (x_wide, x_deep, y) in enumerate(dataloader):\n",
    "        x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
    "        main_preds, aux_preds = model(x_wide, x_deep)\n",
    "        main_loss, aux_loss = loss_fn(main_preds, y), loss_fn(aux_preds, y)\n",
    "        batch_loss = weights[0]*main_loss + weights[1]*aux_loss\n",
    "        total_loss += batch_loss.item()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"Train Loss: {total_loss/num_batches:>.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c1e1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_two_outputs(dataloader, model, loss_fn, weights):\n",
    "    total_loss = 0\n",
    "    num_obs = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_wide, x_deep, y in dataloader:\n",
    "            x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
    "            main_preds, aux_preds = model(x_wide, x_deep)\n",
    "            main_loss, aux_loss = loss_fn(main_preds, y), loss_fn(aux_preds, y)\n",
    "            batch_loss = weights[0]*main_loss + weights[1]*aux_loss\n",
    "            total_loss += batch_loss.item()\n",
    "        out_loss = total_loss / num_batches\n",
    "        print(f'Validation Loss: {out_loss:>.5}')\n",
    "    return out_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8faffe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 1 -----\n",
      "Train Loss: 1.216\n",
      "Validation Loss: 0.98379\n",
      "\n",
      "----- Epoch: 2 -----\n",
      "Train Loss: 0.47435\n",
      "Validation Loss: 0.87124\n",
      "\n",
      "----- Epoch: 3 -----\n",
      "Train Loss: 0.4347\n",
      "Validation Loss: 0.51954\n",
      "\n",
      "----- Epoch: 4 -----\n",
      "Train Loss: 0.42014\n",
      "Validation Loss: 1.1647\n",
      "\n",
      "----- Epoch: 5 -----\n",
      "Train Loss: 0.42987\n",
      "Validation Loss: 1.3167\n",
      "\n",
      "----- Epoch: 6 -----\n",
      "Train Loss: 0.40963\n",
      "Validation Loss: 0.76537\n",
      "\n",
      "----- Epoch: 7 -----\n",
      "Train Loss: 0.39271\n",
      "Validation Loss: 0.36858\n",
      "\n",
      "----- Epoch: 8 -----\n",
      "Train Loss: 0.37555\n",
      "Validation Loss: 0.463\n",
      "\n",
      "----- Epoch: 9 -----\n",
      "Train Loss: 0.3679\n",
      "Validation Loss: 0.57672\n",
      "\n",
      "----- Epoch: 10 -----\n",
      "Train Loss: 0.37029\n",
      "Validation Loss: 0.66761\n",
      "\n",
      "----- Epoch: 11 -----\n",
      "Train Loss: 0.37054\n",
      "Validation Loss: 0.94435\n",
      "\n",
      "----- Epoch: 12 -----\n",
      "Train Loss: 0.35667\n",
      "Validation Loss: 0.8061\n",
      "\n",
      "----- Epoch: 13 -----\n",
      "Train Loss: 0.35229\n",
      "Validation Loss: 1.0195\n",
      "\n",
      "----- Epoch: 14 -----\n",
      "Train Loss: 0.35483\n",
      "Validation Loss: 0.58288\n",
      "\n",
      "----- Epoch: 15 -----\n",
      "Train Loss: 0.35088\n",
      "Validation Loss: 0.65632\n",
      "\n",
      "----- Epoch: 16 -----\n",
      "Train Loss: 0.34793\n",
      "Validation Loss: 0.82769\n",
      "\n",
      "----- Epoch: 17 -----\n",
      "Train Loss: 0.34214\n",
      "Validation Loss: 0.88726\n",
      "\n",
      "----- Epoch: 18 -----\n",
      "Train Loss: 0.34115\n",
      "Validation Loss: 0.6148\n",
      "\n",
      "----- Epoch: 19 -----\n",
      "Train Loss: 0.33767\n",
      "Validation Loss: 0.65026\n",
      "\n",
      "----- Epoch: 20 -----\n",
      "Train Loss: 0.33515\n",
      "Validation Loss: 0.66952\n"
     ]
    }
   ],
   "source": [
    "weights = (0.9, 0.1)\n",
    "for epoch in range(20):\n",
    "    print(f\"\\n----- Epoch: {epoch+1} -----\")\n",
    "    train_two_outputs(wnd_train_loader, multi_output_model, loss_fn, multi_output_optim, weights)\n",
    "    eval_two_outputs(wnd_valid_loader, multi_output_model, loss_fn, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e740c",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model\n",
    "\n",
    "In PyTorch one can save only the learnable weights or both the model and the weights. Full details are given in [this tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html). In both cases, the function to use is `torch.save()`, which serializes its input via pickle. Learnable parameters and *registered buffers* (e.g., the running mean in batch normalization) are stored in the `state_dict()`. Note that optimizers have their own `.state_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "793b3999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer1.weight': torch.Size([30, 6]),\n",
       " 'hidden_layer1.bias': torch.Size([30]),\n",
       " 'hidden_layer2.weight': torch.Size([30, 30]),\n",
       " 'hidden_layer2.bias': torch.Size([30]),\n",
       " 'output_layer.weight': torch.Size([1, 35]),\n",
       " 'output_layer.bias': torch.Size([1]),\n",
       " 'aux_output.weight': torch.Size([1, 30]),\n",
       " 'aux_output.bias': torch.Size([1])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v.shape for k, v in multi_output_model.state_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a77a1c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'param_groups'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_output_optim.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3507fd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_output_optim.state_dict()['state'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0c546d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-07,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False,\n",
       "  'differentiable': False,\n",
       "  'fused': None,\n",
       "  'params': [0, 1, 2, 3, 4, 5, 6, 7]}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_output_optim.state_dict()['param_groups']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ccd0df",
   "metadata": {},
   "source": [
    "To save a `state_dict` to a `PATH` use\n",
    "\n",
    "```python\n",
    "torch.save(model.state_dict(), PATH)\n",
    "```\n",
    "\n",
    "To load the model you must first deserialize the dictionary from `PATH` via `torch.load()`, and then load the dictionary (NOT the path) into the model's state dictionary, as shown below.\n",
    "\n",
    "```python\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "```\n",
    "\n",
    "### Important! Dereferencing the best model\n",
    "\n",
    "If you only plan to keep the best performing model (according to the acquired validation loss), donâ€™t forget that `best_model_state = model.state_dict()` returns a **reference** to the state and not its copy! You must serialize best_model_state or use `best_model_state = deepcopy(model.state_dict())` otherwise your best best_model_state will keep getting updated by the subsequent training iterations. As a result, the final model state will be the state of the overfitted model.\n",
    "\n",
    "### Saving and loading multiple models at once\n",
    "\n",
    "```python\n",
    "# ----- Saving -----\n",
    "torch.save({\n",
    "            'modelA_state_dict': modelA.state_dict(),\n",
    "            'modelB_state_dict': modelB.state_dict(),\n",
    "            'optimizerA_state_dict': optimizerA.state_dict(),\n",
    "            'optimizerB_state_dict': optimizerB.state_dict(),\n",
    "            ...\n",
    "            }, PATH)\n",
    "\n",
    "# ----- Loading -----\n",
    "modelA = TheModelAClass(*args, **kwargs)\n",
    "modelB = TheModelBClass(*args, **kwargs)\n",
    "optimizerA = TheOptimizerAClass(*args, **kwargs)\n",
    "optimizerB = TheOptimizerBClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "modelB.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])\n",
    "\n",
    "modelA.eval()\n",
    "modelB.eval()\n",
    "# - or -\n",
    "modelA.train()\n",
    "modelB.train()\n",
    "\n",
    "```\n",
    "\n",
    "Look the documentation for [warmstarting using a different model](https://pytorch.org/tutorials/beginner/saving_loading_models.html#warmstarting-model-using-parameters-from-a-different-model).\n",
    "\n",
    "## Using Callbacks\n",
    "\n",
    "There are no callbacks in plain PyTorch, but we can obtain the same results with a bit of work.\n",
    "\n",
    "### Model Checkpoint\n",
    "\n",
    "Read this [page](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html) to learn about general checkpointing in PyTorch. To be able to fully recover the state of a model you may want to save\n",
    "\n",
    "1. The model's `state_dict`.\n",
    "2. The optimizer's `state_dict`.\n",
    "3. The epoch.\n",
    "4. The latest recorded training loss.\n",
    "\n",
    "We have complete freedom to store all the information we want in the checkpoint. For example, we may want to structure it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5fbc3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "cp_dir = Path('checkpoints')\n",
    "cp_dir.mkdir(exist_ok=True)\n",
    "cp_path = cp_dir / 'checkpoint.pth'\n",
    "\n",
    "epoch = 20\n",
    "train_loss = 0.33783\n",
    "valid_loss = 0.69521\n",
    "\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': multi_output_model.state_dict(),\n",
    "    'optimizer_state_dict': multi_output_optim.state_dict(),\n",
    "    'train_loss': train_loss,\n",
    "    'valid_loss': valid_loss\n",
    "}, cp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc6da7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\r\n",
      "-rw-rw-r-- 1 giovenko giovenko 23339 May 20 16:15 checkpoint.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d14b6",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "\n",
    "In early stopping we check the performance of a model in terms of validation loss, and if the loss has not improved for a number $n$ of epochs, we stop the training. We refer to $n$ as *patience*.\n",
    "\n",
    "In order to implement early stopping we therefore need to:\n",
    "\n",
    "1. Get the desired patient (int).\n",
    "2. Have a counter that keeps track of the number of epochs since the last minimum validation loss.\n",
    "3. Storage for the best epoch and the best validation loss.\n",
    "4. A mechanism to save a checkpoint every time a new minimum validation loss is achieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e40f3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.best_loss = np.inf\n",
    "        self.best_epoch = np.inf\n",
    "        self.epochs_since_best = 0\n",
    "        \n",
    "    def stop_early(self, epoch, valid_loss):\n",
    "        if valid_loss < self.best_loss:\n",
    "            self.best_loss = valid_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.epochs_since_best = 0\n",
    "        else:\n",
    "            self.epochs_since_best += 1\n",
    "            if self.epochs_since_best == self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd93e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_output_optim = optim.Adam(multi_output_model.parameters(), eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e76bb2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 1 -----\n",
      "Train Loss: 0.33697\n",
      "Validation Loss: 0.50446\n",
      "\n",
      "----- Epoch: 2 -----\n",
      "Train Loss: 0.3305\n",
      "Validation Loss: 1.1231\n",
      "\n",
      "----- Epoch: 3 -----\n",
      "Train Loss: 0.33434\n",
      "Validation Loss: 0.60446\n",
      "\n",
      "----- Epoch: 4 -----\n",
      "Train Loss: 0.33188\n",
      "Validation Loss: 0.71849\n",
      "\n",
      "----- Epoch: 5 -----\n",
      "Train Loss: 0.32739\n",
      "Validation Loss: 0.45381\n",
      "\n",
      "----- Epoch: 6 -----\n",
      "Train Loss: 0.32892\n",
      "Validation Loss: 0.807\n",
      "\n",
      "----- Epoch: 7 -----\n",
      "Train Loss: 0.33477\n",
      "Validation Loss: 0.5289\n",
      "\n",
      "----- Epoch: 8 -----\n",
      "Train Loss: 0.32655\n",
      "Validation Loss: 0.59588\n",
      "\n",
      "----- Epoch: 9 -----\n",
      "Train Loss: 0.32397\n",
      "Validation Loss: 0.33751\n",
      "\n",
      "----- Epoch: 10 -----\n",
      "Train Loss: 0.31995\n",
      "Validation Loss: 0.34055\n",
      "\n",
      "----- Epoch: 11 -----\n",
      "Train Loss: 0.32795\n",
      "Validation Loss: 0.31695\n",
      "\n",
      "----- Epoch: 12 -----\n",
      "Train Loss: 0.32118\n",
      "Validation Loss: 0.30978\n",
      "\n",
      "----- Epoch: 13 -----\n",
      "Train Loss: 0.32118\n",
      "Validation Loss: 0.39125\n",
      "\n",
      "----- Epoch: 14 -----\n",
      "Train Loss: 0.32002\n",
      "Validation Loss: 0.32176\n",
      "\n",
      "----- Epoch: 15 -----\n",
      "Train Loss: 0.31795\n",
      "Validation Loss: 0.32378\n",
      "\n",
      "----- Epoch: 16 -----\n",
      "Train Loss: 0.31616\n",
      "Validation Loss: 0.36227\n",
      "\n",
      "----- Epoch: 17 -----\n",
      "Train Loss: 0.32065\n",
      "Validation Loss: 0.49104\n"
     ]
    }
   ],
   "source": [
    "weights = (0.9, 0.1)\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(f\"\\n----- Epoch: {epoch+1} -----\")\n",
    "    train_two_outputs(wnd_train_loader, multi_output_model, loss_fn, multi_output_optim, weights)\n",
    "    valid_loss = eval_two_outputs(wnd_valid_loader, multi_output_model, loss_fn, weights)\n",
    "    if early_stopping.stop_early(epoch, valid_loss):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf78cad",
   "metadata": {},
   "source": [
    "## Using TensorBoard\n",
    "\n",
    "TO CHECK: tensorboard runs fine inside a colab notebook, but I didn't manage to make it run inside jupyter because of some authentication issues. Check how to fix this. The commands I added were:\n",
    "\n",
    "```\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./runs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12f203b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 1 -----\n",
      "Train Loss: 0.31981\n",
      "Validation Loss: 0.32612\n",
      "\n",
      "----- Epoch: 2 -----\n",
      "Train Loss: 0.31697\n",
      "Validation Loss: 0.44084\n",
      "\n",
      "----- Epoch: 3 -----\n",
      "Train Loss: 0.315\n",
      "Validation Loss: 0.31956\n",
      "\n",
      "----- Epoch: 4 -----\n",
      "Train Loss: 0.31264\n",
      "Validation Loss: 0.44518\n",
      "\n",
      "----- Epoch: 5 -----\n",
      "Train Loss: 0.3129\n",
      "Validation Loss: 0.41059\n",
      "\n",
      "----- Epoch: 6 -----\n",
      "Train Loss: 0.32542\n",
      "Validation Loss: 0.50554\n",
      "\n",
      "----- Epoch: 7 -----\n",
      "Train Loss: 0.31735\n",
      "Validation Loss: 0.49812\n",
      "\n",
      "----- Epoch: 8 -----\n",
      "Train Loss: 0.31118\n",
      "Validation Loss: 0.485\n",
      "\n",
      "----- Epoch: 9 -----\n",
      "Train Loss: 0.30901\n",
      "Validation Loss: 0.32526\n",
      "\n",
      "----- Epoch: 10 -----\n",
      "Train Loss: 0.31156\n",
      "Validation Loss: 0.31697\n",
      "\n",
      "----- Epoch: 11 -----\n",
      "Train Loss: 0.30832\n",
      "Validation Loss: 0.47582\n",
      "\n",
      "----- Epoch: 12 -----\n",
      "Train Loss: 0.30746\n",
      "Validation Loss: 0.38116\n",
      "\n",
      "----- Epoch: 13 -----\n",
      "Train Loss: 0.30627\n",
      "Validation Loss: 0.29644\n",
      "\n",
      "----- Epoch: 14 -----\n",
      "Train Loss: 0.30588\n",
      "Validation Loss: 0.31179\n",
      "\n",
      "----- Epoch: 15 -----\n",
      "Train Loss: 0.30666\n",
      "Validation Loss: 0.31057\n",
      "\n",
      "----- Epoch: 16 -----\n",
      "Train Loss: 0.30784\n",
      "Validation Loss: 0.46307\n",
      "\n",
      "----- Epoch: 17 -----\n",
      "Train Loss: 0.30644\n",
      "Validation Loss: 0.90901\n",
      "\n",
      "----- Epoch: 18 -----\n",
      "Train Loss: 0.30535\n",
      "Validation Loss: 1.0641\n",
      "\n",
      "----- Epoch: 19 -----\n",
      "Train Loss: 0.31083\n",
      "Validation Loss: 0.59555\n",
      "\n",
      "----- Epoch: 20 -----\n",
      "Train Loss: 0.30425\n",
      "Validation Loss: 0.57414\n"
     ]
    }
   ],
   "source": [
    "multi_output_optim = optim.Adam(multi_output_model.parameters(), eps=1e-7)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(20):\n",
    "    print(f\"\\n----- Epoch: {epoch+1} -----\")\n",
    "    train_two_outputs(wnd_train_loader, multi_output_model, loss_fn, multi_output_optim, weights)\n",
    "    valid_loss = eval_two_outputs(wnd_valid_loader, multi_output_model, loss_fn, weights)\n",
    "    writer.add_scalar('Validation Loss', valid_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "147953c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d61a19fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cb2f68a6b50e26a0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cb2f68a6b50e26a0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205e10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
